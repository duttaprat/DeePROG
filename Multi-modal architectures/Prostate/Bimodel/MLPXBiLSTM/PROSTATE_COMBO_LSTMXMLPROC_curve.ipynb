{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from path import Path\n",
    "import torch.utils.data as data\n",
    "from imageio import imread\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from PIL import *\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from path import Path\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "df=pd.DataFrame()\n",
    "azz={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(y_test,y_score,n_classes):\n",
    "    \n",
    "    \n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    lb = LabelBinarizer()\n",
    "    y_test=lb.fit_transform(y_test)\n",
    "    \n",
    "    y_test = np.hstack((1 - y_test, y_test))\n",
    "    \n",
    "#     y_test=lb.inverse_transform(y_test[:, 0])\n",
    "#     print(y_test.shape)\n",
    "#     print(y_test)    \n",
    "#     print(y_test[:, 0])\n",
    "#     print(y_score[:, 0])\n",
    "#     print(y_score[:, 1])\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    # Finally average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "    # Plot all ROC curves\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "             label='micro-average ROC curve (area = {0:0.2f})'\n",
    "                   ''.format(roc_auc[\"micro\"]),\n",
    "             color='deeppink', linestyle=':', linewidth=4)\n",
    "    azz['fpr']=fpr['macro']\n",
    "    azz['tpr']=tpr['macro']\n",
    "\n",
    "    plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "             label='macro-average ROC curve (area = {0:0.2f})'\n",
    "                   ''.format(roc_auc[\"macro\"]),\n",
    "             color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "    colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "    print(n_classes,\"yes\")\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        print(i)\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "                 label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                 ''.format(i, roc_auc[i]))\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('LSTM X MLP  FOR  PROSTATE  DATASET')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    ''' Scaled Dot-Product Attention '''\n",
    "    # given query, key,value it finds the rightful weighted component of v to get the attention applied ouput\n",
    "    #q,v,k- batch X length of sequence X features or encoding\n",
    "    #attention sholuld be -batchX7X7\n",
    "    def __init__(self, temperature, attn_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.dropout = nn.Dropout(attn_dropout)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "#         print(k.transpose(1,2).shape)\n",
    "\n",
    "        attn = torch.bmm(q, k.transpose(1, 2)) \n",
    "#         print(attn.shape)\n",
    "        attn = attn / self.temperature\n",
    "\n",
    "        if mask is not None:\n",
    "            attn = attn.masked_fill(mask, -np.inf)\n",
    "\n",
    "        attn = self.softmax(attn)\n",
    "        attn = self.dropout(attn)\n",
    "#         print(str(attn.shape)+\" \"+str(v.shape))\n",
    "        output = torch.bmm(attn, v)\n",
    "\n",
    "        return output, attn\n",
    "SDP=ScaledDotProductAttention(5)\n",
    "Ss=SDP(torch.zeros(5,6,100),torch.zeros(5,6,100),torch.zeros(5,6,100))\n",
    "# print(Ss[0].shape)\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    ''' Multi-Head Attention module '''\n",
    "\n",
    "    def __init__(self, n_head, d_model, d_k, d_v, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_head = n_head\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "\n",
    "        self.w_qs = nn.Linear(d_model, n_head * d_k)\n",
    "        self.w_ks = nn.Linear(d_model, n_head * d_k)\n",
    "        self.w_vs = nn.Linear(d_model, n_head * d_v)\n",
    "        nn.init.normal_(self.w_qs.weight, mean=0, std=np.sqrt(2.0 / (d_model + d_k)))\n",
    "        nn.init.normal_(self.w_ks.weight, mean=0, std=np.sqrt(2.0 / (d_model + d_k)))\n",
    "        nn.init.normal_(self.w_vs.weight, mean=0, std=np.sqrt(2.0 / (d_model + d_v)))\n",
    "\n",
    "        self.attention = ScaledDotProductAttention(temperature=np.power(d_k, 0.5))\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.fc = nn.Linear(n_head * d_v, d_model)\n",
    "        nn.init.xavier_normal_(self.fc.weight)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "\n",
    "        d_k, d_v, n_head = self.d_k, self.d_v, self.n_head\n",
    "\n",
    "        sz_b, len_q, _ = q.size()\n",
    "        sz_b, len_k, _ = k.size()\n",
    "        sz_b, len_v, _ = v.size()\n",
    "#         print(str(sz_b)+\"die\")\n",
    "\n",
    "        residual = q\n",
    "\n",
    "        q = self.w_qs(q).view(sz_b, len_q, n_head, d_k)\n",
    "        k = self.w_ks(k).view(sz_b, len_k, n_head, d_k)\n",
    "        v = self.w_vs(v).view(sz_b, len_v, n_head, d_v)\n",
    "\n",
    "        q = q.permute(2, 0, 1, 3).contiguous().view(-1, len_q, d_k) # (n*b) x lq x dk\n",
    "        k = k.permute(2, 0, 1, 3).contiguous().view(-1, len_k, d_k) # (n*b) x lk x dk\n",
    "        v = v.permute(2, 0, 1, 3).contiguous().view(-1, len_v, d_v) # (n*b) x lv x dv\n",
    "#         print(\"v-\"+str(v.shape))\n",
    "        if mask is not None:\n",
    "            mask = mask.repeat(n_head, 1, 1) # (n*b) x .. x ..\n",
    "        output, attn = self.attention(q, k, v, mask=mask)\n",
    "#         print(q.shape,k.shape,v.shape)\n",
    "        output = output.view(n_head, sz_b, len_q, d_v)\n",
    "        output = output.permute(1, 2, 0, 3).contiguous().view(sz_b, len_q, -1) # b x lq x (n*dv)\n",
    "\n",
    "        output = self.dropout(self.fc(output))\n",
    "        output = self.layer_norm(output + residual)\n",
    "\n",
    "        return output, attn\n",
    "MHA=MultiHeadAttention(4,15,15,15)\n",
    "op=MHA(torch.zeros(5,7,15),torch.zeros(5,7,15),torch.zeros(5,7,15))\n",
    "# print(op[0].shape)\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    ''' A two-feed-forward-layer module '''\n",
    "\n",
    "    def __init__(self, d_in, d_hid, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.w_1 = nn.Conv1d(d_in, d_hid, 1) # position-wise\n",
    "        self.w_2 = nn.Conv1d(d_hid, d_in, 1) # position-wise\n",
    "        self.layer_norm = nn.LayerNorm(d_in)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        output = x.transpose(1, 2)\n",
    "#         print(\"FCC-\"+str(output.shape))\n",
    "#         print(\"FFC_out-\"+str(self.w_1(output).shape))\n",
    "        output = self.w_2(F.relu(self.w_1(output)))\n",
    "        output = output.transpose(1, 2)\n",
    "        output = self.dropout(output)\n",
    "        output = self.layer_norm(output + residual)\n",
    "        return output\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    ''' Compose with two layers '''\n",
    "\n",
    "    def __init__(self, d_model, d_inner, n_head, d_k, d_v, dropout=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.slf_attn = MultiHeadAttention(\n",
    "            n_head, d_model, d_k, d_v, dropout=dropout)\n",
    "        self.pos_ffn = PositionwiseFeedForward(d_model, d_inner, dropout=dropout)\n",
    "\n",
    "    def forward(self, enc_input, non_pad_mask=None, slf_attn_mask=None):\n",
    "        enc_output, enc_slf_attn = self.slf_attn(\n",
    "            enc_input, enc_input, enc_input, mask=slf_attn_mask)\n",
    "#         print(\"ENC_o\")\n",
    "#         print(enc_output.shape)\n",
    "\n",
    "\n",
    "        enc_output = self.pos_ffn(enc_output)\n",
    "\n",
    "\n",
    "        return enc_output, enc_slf_attn\n",
    "    \n",
    "XX=EncoderLayer(15,10,4,10,10)\n",
    "\n",
    "zz=XX(torch.zeros(5,7,15))\n",
    "# print(\"ENc\")\n",
    "# print(zz[0].shape)\n",
    "# print(\"start\")\n",
    "class Encoder(nn.Module):\n",
    "    ''' A encoder model with self attention mechanism. '''\n",
    "\n",
    "    def __init__(self,n_modality,d_model,n_head,d_k,d_v,dropout,n_layers,d_inner=500):\n",
    "        #d_model - number of features in input 100 here\n",
    "        #n_head - number of heads of multihaded attention\n",
    "        #d_k=d_q=  number of features in query, key\n",
    "        #d_v = number of features in value whose weighted(attentioned) sum we gonna take\n",
    "        \n",
    "\n",
    "        super().__init__()\n",
    "        self.n_modality=n_modality\n",
    "#         self.stn=nn.ModuleList([SpatialTransformer(3, (240,240), 8) for _ in range(n_ref)])\n",
    "        \n",
    "        self.layer_stack = nn.ModuleList([EncoderLayer(d_model, d_inner, n_head, d_k, d_v, dropout=dropout) \n",
    "                                          for _ in range(n_layers)])\n",
    "#         self.em=nn.Linear(225,100)\n",
    "        self.fc1=nn.Linear(d_model*n_modality,300)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.fc2=nn.Linear(300,100)\n",
    "        self.fc3=nn.Linear(100,2)\n",
    "#         self.fc4=nn.Linear(50,3)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=300)\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=100)\n",
    "        self.softmax=nn.Softmax(1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, embeddings1,embeddings2 ):\n",
    "\n",
    "\n",
    "        \n",
    "        encodings_total=[embeddings1,embeddings2]\n",
    "\n",
    "        enc_output=torch.stack(encodings_total,0)\n",
    "\n",
    "        \n",
    "        enc_output=enc_output.permute(1,0,2)\n",
    "#         print(\"encoding_OUTPUT2-\"+str(enc_output.shape))\n",
    "\n",
    "        for enc_layer in self.layer_stack:\n",
    "            enc_output, enc_slf_attn = enc_layer(enc_output,non_pad_mask=None,slf_attn_mask=None)\n",
    "           \n",
    "        \n",
    "        final_input=enc_output.reshape(enc_output.shape[0],-1)\n",
    "\n",
    "        final=self.relu(self.fc3(self.bn2(self.relu((self.fc2(self.bn1(self.relu(self.fc1(final_input)))))))))\n",
    "        \n",
    "        return(final)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 100])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1=torch.zeros(4,100)\n",
    "e2=torch.zeros(4,100)\n",
    "e3=torch.stack([e1,e2],0)\n",
    "e3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_name</th>\n",
       "      <th>tag_0</th>\n",
       "      <th>tag_1</th>\n",
       "      <th>tag_2</th>\n",
       "      <th>tag_3</th>\n",
       "      <th>tag_4</th>\n",
       "      <th>tag_5</th>\n",
       "      <th>tag_6</th>\n",
       "      <th>tag_7</th>\n",
       "      <th>tag_8</th>\n",
       "      <th>...</th>\n",
       "      <th>tag_90</th>\n",
       "      <th>tag_91</th>\n",
       "      <th>tag_92</th>\n",
       "      <th>tag_93</th>\n",
       "      <th>tag_94</th>\n",
       "      <th>tag_95</th>\n",
       "      <th>tag_96</th>\n",
       "      <th>tag_97</th>\n",
       "      <th>tag_98</th>\n",
       "      <th>tag_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhl</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.241405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.266189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smox</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.911898</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.720570</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>znf148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.678095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.640351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>map4k2</td>\n",
       "      <td>20.404165</td>\n",
       "      <td>23.852463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.247234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.033705</td>\n",
       "      <td>0.203660</td>\n",
       "      <td>56.684559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.108454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.755461</td>\n",
       "      <td>5.603198</td>\n",
       "      <td>13.697145</td>\n",
       "      <td>63.017044</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mapk4</td>\n",
       "      <td>42.203545</td>\n",
       "      <td>52.076824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>89.526337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.578827</td>\n",
       "      <td>10.026752</td>\n",
       "      <td>108.900192</td>\n",
       "      <td>...</td>\n",
       "      <td>3.838364</td>\n",
       "      <td>40.393089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.628872</td>\n",
       "      <td>18.609310</td>\n",
       "      <td>32.895622</td>\n",
       "      <td>120.597061</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  gene_name      tag_0      tag_1  tag_2      tag_3      tag_4  tag_5  \\\n",
       "0       vhl   0.000000   0.000000    0.0  22.241405   0.000000    0.0   \n",
       "1      smox   0.000000   0.000000    0.0   0.000000   0.000000    0.0   \n",
       "2    znf148   0.000000   0.000000    0.0  21.678095   0.000000    0.0   \n",
       "3    map4k2  20.404165  23.852463    0.0   0.000000  43.247234    0.0   \n",
       "4     mapk4  42.203545  52.076824    0.0   0.000000  89.526337    0.0   \n",
       "\n",
       "       tag_6      tag_7       tag_8  ...    tag_90     tag_91  tag_92  tag_93  \\\n",
       "0   0.000000   0.000000    0.000000  ...  0.000000   0.000000     0.0     0.0   \n",
       "1   0.000000   0.000000    7.911898  ...  0.000000   0.000000     0.0     0.0   \n",
       "2   0.000000   0.000000    0.000000  ...  0.000000   0.000000     0.0     0.0   \n",
       "3  31.033705   0.203660   56.684559  ...  0.000000  18.108454     0.0     0.0   \n",
       "4  67.578827  10.026752  108.900192  ...  3.838364  40.393089     0.0     0.0   \n",
       "\n",
       "   tag_94     tag_95     tag_96     tag_97      tag_98     tag_99  \n",
       "0     0.0   0.000000   0.000000   0.000000    0.000000  10.266189  \n",
       "1     0.0   0.000000   0.000000   0.000000   12.720570   0.000000  \n",
       "2     0.0   0.000000   0.000000   0.000000    0.000000  10.640351  \n",
       "3     0.0  28.755461   5.603198  13.697145   63.017044   0.000000  \n",
       "4     0.0  57.628872  18.609310  32.895622  120.597061   0.000000  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_set_MLP=pd.read_csv('Prostrate_MLP_features_ankit.csv')\n",
    "feature_set_LSTM=pd.read_csv('prostrate_LSTM_features_ankit.csv')\n",
    "feature_set_MLP.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_name</th>\n",
       "      <th>tag_0</th>\n",
       "      <th>tag_1</th>\n",
       "      <th>tag_2</th>\n",
       "      <th>tag_3</th>\n",
       "      <th>tag_4</th>\n",
       "      <th>tag_5</th>\n",
       "      <th>tag_6</th>\n",
       "      <th>tag_7</th>\n",
       "      <th>tag_8</th>\n",
       "      <th>...</th>\n",
       "      <th>tag_90</th>\n",
       "      <th>tag_91</th>\n",
       "      <th>tag_92</th>\n",
       "      <th>tag_93</th>\n",
       "      <th>tag_94</th>\n",
       "      <th>tag_95</th>\n",
       "      <th>tag_96</th>\n",
       "      <th>tag_97</th>\n",
       "      <th>tag_98</th>\n",
       "      <th>tag_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhl</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.241405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.266189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smox</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.911898</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.720570</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>znf148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.678095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.640351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>map4k2</td>\n",
       "      <td>20.404165</td>\n",
       "      <td>23.852463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.247234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.033705</td>\n",
       "      <td>0.203660</td>\n",
       "      <td>56.684559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.108454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.755461</td>\n",
       "      <td>5.603198</td>\n",
       "      <td>13.697145</td>\n",
       "      <td>63.017044</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mapk4</td>\n",
       "      <td>42.203545</td>\n",
       "      <td>52.076824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>89.526337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.578827</td>\n",
       "      <td>10.026752</td>\n",
       "      <td>108.900192</td>\n",
       "      <td>...</td>\n",
       "      <td>3.838364</td>\n",
       "      <td>40.393089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.628872</td>\n",
       "      <td>18.609310</td>\n",
       "      <td>32.895622</td>\n",
       "      <td>120.597061</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  gene_name      tag_0      tag_1  tag_2      tag_3      tag_4  tag_5  \\\n",
       "0       vhl   0.000000   0.000000    0.0  22.241405   0.000000    0.0   \n",
       "1      smox   0.000000   0.000000    0.0   0.000000   0.000000    0.0   \n",
       "2    znf148   0.000000   0.000000    0.0  21.678095   0.000000    0.0   \n",
       "3    map4k2  20.404165  23.852463    0.0   0.000000  43.247234    0.0   \n",
       "4     mapk4  42.203545  52.076824    0.0   0.000000  89.526337    0.0   \n",
       "\n",
       "       tag_6      tag_7       tag_8  ...    tag_90     tag_91  tag_92  tag_93  \\\n",
       "0   0.000000   0.000000    0.000000  ...  0.000000   0.000000     0.0     0.0   \n",
       "1   0.000000   0.000000    7.911898  ...  0.000000   0.000000     0.0     0.0   \n",
       "2   0.000000   0.000000    0.000000  ...  0.000000   0.000000     0.0     0.0   \n",
       "3  31.033705   0.203660   56.684559  ...  0.000000  18.108454     0.0     0.0   \n",
       "4  67.578827  10.026752  108.900192  ...  3.838364  40.393089     0.0     0.0   \n",
       "\n",
       "   tag_94     tag_95     tag_96     tag_97      tag_98     tag_99  \n",
       "0     0.0   0.000000   0.000000   0.000000    0.000000  10.266189  \n",
       "1     0.0   0.000000   0.000000   0.000000   12.720570   0.000000  \n",
       "2     0.0   0.000000   0.000000   0.000000    0.000000  10.640351  \n",
       "3     0.0  28.755461   5.603198  13.697145   63.017044   0.000000  \n",
       "4     0.0  57.628872  18.609310  32.895622  120.597061   0.000000  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_set_MLP.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2424, 100)\n",
      "2424\n"
     ]
    }
   ],
   "source": [
    "header_of_MLP=['tag_'+str(i) for i in range(feature_set_MLP.shape[1]-1)]\n",
    "features_MLP=np.array(feature_set_MLP[header_of_MLP])\n",
    "gene_MLP=feature_set_MLP['gene_name']\n",
    "print(features_MLP.shape)\n",
    "print(len(gene_MLP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_MLP={}\n",
    "u=0\n",
    "for gn in gene_MLP:\n",
    "    dictionary_MLP[gn]=features_MLP[u]\n",
    "    u=u+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1763, 100)\n",
      "1763\n"
     ]
    }
   ],
   "source": [
    "header_of_LSTM=['tag_'+str(i) for i in range(feature_set_LSTM.shape[1]-1)]\n",
    "features_LSTM=np.array(feature_set_LSTM[header_of_LSTM])\n",
    "gene_LSTM=feature_set_LSTM['gene_name']\n",
    "print(features_LSTM.shape)\n",
    "print(len(gene_LSTM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107\n"
     ]
    }
   ],
   "source": [
    "dictionary_LSTM={}\n",
    "u=f=0\n",
    "for gn in gene_LSTM:\n",
    "    if gn in dictionary_LSTM.keys():\n",
    "#         print(gn)\n",
    "        f=f+1\n",
    "    dictionary_LSTM[gn]=features_LSTM[u]\n",
    "    u=u+1\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1656\n"
     ]
    }
   ],
   "source": [
    "print(len(dictionary_LSTM.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2424,)\n"
     ]
    }
   ],
   "source": [
    "fil=open('../../Multi-modality/Model/Prostrate/uni model/MLP/Labels_prostate.txt','r')\n",
    "tmp=list()\n",
    "for line in fil:\n",
    "\ttmp.append(int(line))\n",
    "\n",
    "label_PROSTRATE=np.array(tmp)\n",
    "print(label_PROSTRATE.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "787 976 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1763"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Sequenceloader(data.Dataset):\n",
    "    def __init__(self,GN,Feat,label):\n",
    "        self.gene_names=GN\n",
    "        self.features_mlp=Feat\n",
    "        self.label=label\n",
    "        self.coincdgene_name=[]\n",
    "        self.coincidfeature_MLP=[]\n",
    "        self.coincidfeature_LSTM=[]\n",
    "        self.coincidlabel=[]\n",
    "        for i in range(len(self.gene_names)):\n",
    "            u=self.gene_names[i]\n",
    "            if u in dictionary_LSTM.keys():\n",
    "                \n",
    " \n",
    "                ch=1   \n",
    "                for jj in range(ch):\n",
    "                    self.coincdgene_name.append(u)\n",
    "                    self.coincidfeature_MLP.append(self.features_mlp[i])\n",
    "                    self.coincidfeature_LSTM.append(dictionary_LSTM[u])\n",
    "                    self.coincidlabel.append(self.label[i])\n",
    "        \n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "#         print(len(self.dataset))\n",
    "        return len(self.coincdgene_name)       \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "         return np.array(self.coincidfeature_MLP[index]),np.array(self.coincidfeature_LSTM[index]),np.array(self.coincidlabel[index])\n",
    "#         print(self.dataset['gen_name'][index])          \n",
    "#         try:\n",
    "           \n",
    "#         except :\n",
    "            \n",
    "total_set=Sequenceloader(gene_MLP,features_MLP,label_PROSTRATE)  \n",
    "a=b=c=0\n",
    "for x,y,z in total_set:\n",
    "    if(z==0):\n",
    "        a=a+1\n",
    "    elif z==1:\n",
    "        b=b+1\n",
    "    else:\n",
    "        c=c+1\n",
    "print(a,b,c)\n",
    "a+b    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(total_set)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(total_set, batch_size=batch_size, \n",
    "                                           sampler=train_sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(total_set, batch_size=batch_size,\n",
    "                                                sampler=valid_sampler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4])\n",
      "torch.Size([3, 100]) torch.Size([3, 100]) torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "for a,b,c in train_loader:\n",
    "    print(a.shape,b.shape,c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device='cuda:7'\n",
    "model_lstmXMLP=Encoder(2,100,4,300,300,True,4).to(device) #1)mlp 2lstm\n",
    "uz=torch.rand(4, 100).to(device)\n",
    "vz=torch.rand(4,100).to(device)\n",
    "model_lstmXMLP(vz,uz).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_lstmXMLP.load_state_dict(torch.load(Path('1ANKIT_PROSTATE COMBO_LSTMXMLP.pt')))\n",
    "optim_params = [\n",
    "    {'params': model_lstmXMLP.parameters(), 'lr': 0.0001}\n",
    "]\n",
    "optimizer = torch.optim.Adam(optim_params)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.4344,  0.0000],\n",
      "        [10.1609,  0.0000],\n",
      "        [ 0.0000,  2.2215],\n",
      "        [ 0.0000,  7.5673]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 2.3189],\n",
      "        [4.7264, 0.0000],\n",
      "        [0.0000, 3.7030],\n",
      "        [0.0000, 5.2112]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[ 0.0000,  0.0000],\n",
      "        [ 5.5760,  0.0000],\n",
      "        [10.1040,  1.4130],\n",
      "        [ 2.3208,  0.2899]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 6.7284],\n",
      "        [0.0000, 6.9073],\n",
      "        [6.0401, 0.0000],\n",
      "        [0.0000, 0.0000]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 6.2221],\n",
      "        [0.0000, 3.3356],\n",
      "        [0.0000, 6.7128],\n",
      "        [5.1115, 0.0000]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 5.3315],\n",
      "        [6.9830, 0.0000],\n",
      "        [5.6305, 0.0000],\n",
      "        [0.0000, 9.9874]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 6.5986],\n",
      "        [0.0000, 9.0050],\n",
      "        [0.0000, 1.6047],\n",
      "        [9.0243, 0.0000]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[3.3679, 0.0000],\n",
      "        [6.7624, 0.0000],\n",
      "        [0.0000, 7.4448],\n",
      "        [0.6008, 1.2766]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.9062, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [6.0127, 2.8889],\n",
      "        [8.9486, 1.4283]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 7.0877],\n",
      "        [0.0000, 0.0000],\n",
      "        [2.1756, 9.7109],\n",
      "        [0.0000, 5.4580]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 7.3118],\n",
      "        [0.0000, 2.0513],\n",
      "        [5.3226, 0.0000],\n",
      "        [0.0000, 7.1343]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 0.0000],\n",
      "        [0.0000, 6.1691],\n",
      "        [0.0000, 7.6535],\n",
      "        [0.0000, 9.4010]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[ 0.0000, 10.4490],\n",
      "        [ 0.9583,  3.9785],\n",
      "        [10.1721,  0.0000],\n",
      "        [ 4.3233,  0.0000]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[ 0.0000,  9.7111],\n",
      "        [11.2323,  0.0000],\n",
      "        [ 0.0000,  9.0434],\n",
      "        [ 0.0000,  3.5004]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 6.8636],\n",
      "        [0.0000, 6.2862],\n",
      "        [7.7432, 0.0000],\n",
      "        [1.5863, 0.0000]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[7.3431, 0.0000],\n",
      "        [0.0000, 6.9305],\n",
      "        [0.0000, 3.6490],\n",
      "        [0.0000, 2.5644]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 6.5539],\n",
      "        [0.0000, 7.4070],\n",
      "        [9.6163, 0.0000],\n",
      "        [0.0000, 6.1602]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 4.9906],\n",
      "        [9.9085, 0.0000],\n",
      "        [0.0000, 8.1649],\n",
      "        [0.0000, 8.9862]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 7.4826],\n",
      "        [0.0000, 1.5837],\n",
      "        [6.6218, 0.0000],\n",
      "        [9.8890, 0.0000]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 4.1114],\n",
      "        [0.0000, 0.5349]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[4.4663, 0.0000],\n",
      "        [8.4147, 0.0000],\n",
      "        [0.0000, 4.8115],\n",
      "        [0.0000, 4.7869]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[11.7693,  0.0000],\n",
      "        [ 0.0000,  5.9710],\n",
      "        [ 0.0000,  4.5602],\n",
      "        [ 5.0048,  0.0000]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 4.8224],\n",
      "        [5.6187, 0.0000],\n",
      "        [0.0000, 7.5136],\n",
      "        [0.0000, 3.9087]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 4.2337],\n",
      "        [0.0000, 8.8530],\n",
      "        [0.0000, 7.9797],\n",
      "        [9.0917, 0.0000]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[2.5518, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 5.8822],\n",
      "        [1.9416, 0.0000]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 5.7115],\n",
      "        [0.0000, 0.0000],\n",
      "        [4.0928, 0.0000],\n",
      "        [0.0000, 9.0260]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[ 0.0000,  6.1239],\n",
      "        [ 0.0000,  8.2199],\n",
      "        [ 6.5163,  0.0000],\n",
      "        [10.9017,  0.0000]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 7.6187],\n",
      "        [9.6834, 0.0000],\n",
      "        [0.0000, 5.1962],\n",
      "        [0.0000, 6.7461]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[8.1109, 0.0000],\n",
      "        [2.6380, 7.0022],\n",
      "        [0.0000, 2.0387],\n",
      "        [2.1778, 0.0000]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[ 0.0000,  7.6275],\n",
      "        [ 0.0000, 11.8597],\n",
      "        [ 2.5054,  0.0000],\n",
      "        [ 5.3636,  0.0000]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 3.5934],\n",
      "        [0.0000, 3.2629],\n",
      "        [4.1894, 0.0000],\n",
      "        [0.0000, 7.3502]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 0.0000],\n",
      "        [1.8459, 7.5967],\n",
      "        [0.0000, 6.6115],\n",
      "        [0.0000, 0.0000]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 0.0000],\n",
      "        [0.0000, 9.6160],\n",
      "        [3.6302, 0.0000],\n",
      "        [4.3144, 1.1826]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[7.1025, 0.0000],\n",
      "        [1.9498, 1.1766],\n",
      "        [0.0000, 8.6161],\n",
      "        [2.8976, 0.0000]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[ 0.0000,  8.5416],\n",
      "        [ 5.3196,  0.0000],\n",
      "        [ 3.6283,  0.0000],\n",
      "        [ 0.0000, 11.0887]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[7.8052, 2.2817],\n",
      "        [0.0000, 6.7166],\n",
      "        [0.0000, 0.0000],\n",
      "        [6.6097, 0.0000]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[ 0.0000,  6.9429],\n",
      "        [ 8.8995,  0.0000],\n",
      "        [12.0931,  0.0000],\n",
      "        [ 0.0000,  4.5222]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.7794, 0.0000],\n",
      "        [0.3827, 0.0000],\n",
      "        [6.9048, 0.0000],\n",
      "        [0.0000, 0.0000]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[ 8.3265,  0.0000],\n",
      "        [ 4.4088,  0.0000],\n",
      "        [ 0.0000, 14.2274],\n",
      "        [ 0.0000,  9.0663]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[ 0.0000,  8.2893],\n",
      "        [ 0.0000,  7.6763],\n",
      "        [ 0.0000,  4.2524],\n",
      "        [10.6330,  0.0000]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 9.4916],\n",
      "        [8.7012, 0.0000],\n",
      "        [0.0000, 4.0653],\n",
      "        [0.0000, 5.3756]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 0.0000],\n",
      "        [4.9349, 0.0000],\n",
      "        [0.0000, 7.8276],\n",
      "        [0.0000, 7.2782]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[ 3.5081,  2.9001],\n",
      "        [ 0.0000, 10.5863],\n",
      "        [10.6934,  0.0000],\n",
      "        [ 4.7097,  0.0000]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[4.9326, 0.0000],\n",
      "        [8.0817, 0.0000],\n",
      "        [0.0000, 5.7769],\n",
      "        [8.2735, 0.0000]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0492, 1.2960],\n",
      "        [0.0000, 3.7810],\n",
      "        [0.0000, 7.2547],\n",
      "        [1.8502, 0.0000]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 5.5574],\n",
      "        [9.0040, 0.0000],\n",
      "        [6.9601, 0.0000],\n",
      "        [0.0000, 3.3600]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[ 6.3344,  1.0666],\n",
      "        [ 6.2244,  0.0000],\n",
      "        [ 0.0000, 10.6112],\n",
      "        [ 6.7931,  0.0000]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[ 0.0000,  7.6819],\n",
      "        [10.5402,  0.0000],\n",
      "        [ 0.0000, 11.2552],\n",
      "        [ 9.4311,  0.0000]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[1.4288, 0.0000],\n",
      "        [0.0000, 4.4347],\n",
      "        [7.9249, 0.0000],\n",
      "        [8.9890, 0.0000]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[ 0.0000,  8.7003],\n",
      "        [ 0.0000,  8.2118],\n",
      "        [10.0669,  0.0000],\n",
      "        [ 8.8851,  0.0000]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[ 0.0000,  3.8020],\n",
      "        [ 4.5243,  0.0000],\n",
      "        [ 1.1157,  2.4577],\n",
      "        [ 0.0000, 11.5843]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[6.6720, 0.0000],\n",
      "        [0.0000, 7.6606],\n",
      "        [7.4578, 0.0000],\n",
      "        [0.0000, 1.7780]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 3.7325],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 6.7469],\n",
      "        [6.8882, 0.0000]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[ 7.8398,  0.0000],\n",
      "        [ 0.0000, 11.2978],\n",
      "        [ 4.8542,  0.6206],\n",
      "        [ 8.1362,  0.0000]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.6654, 0.0000],\n",
      "        [0.0000, 6.0656],\n",
      "        [0.0000, 5.5019],\n",
      "        [2.4171, 9.0638]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[ 0.0000,  9.1012],\n",
      "        [ 3.7706,  1.0667],\n",
      "        [ 8.0228,  0.0000],\n",
      "        [11.7711,  0.0000]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[ 1.5448,  0.0000],\n",
      "        [ 6.1389,  2.0684],\n",
      "        [12.7446,  3.2400],\n",
      "        [ 0.0000,  2.3428]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 0.7295],\n",
      "        [0.0000, 8.4020],\n",
      "        [7.1841, 1.9469],\n",
      "        [7.8460, 0.0000]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 8.0165],\n",
      "        [0.0000, 5.1895],\n",
      "        [0.0000, 6.7105],\n",
      "        [6.2487, 0.0000]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[8.5682, 0.0000],\n",
      "        [2.9600, 0.0000],\n",
      "        [0.0000, 8.3260],\n",
      "        [0.0000, 6.0142]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[8.9211, 0.0000],\n",
      "        [0.0000, 5.5519],\n",
      "        [0.0000, 8.1944],\n",
      "        [7.1511, 0.0000]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 4.8675],\n",
      "        [0.0000, 6.9406],\n",
      "        [0.1800, 0.0000],\n",
      "        [0.0000, 3.8232]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[5.1834, 0.0000],\n",
      "        [0.0000, 7.9699],\n",
      "        [4.3456, 1.5987],\n",
      "        [9.7948, 0.0000]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 5.4610],\n",
      "        [0.0000, 2.8571],\n",
      "        [6.3044, 0.0000],\n",
      "        [0.0000, 5.0668]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[7.5823, 0.0000],\n",
      "        [0.0000, 8.7680],\n",
      "        [0.0000, 9.7052],\n",
      "        [0.0000, 2.0725]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[ 8.6800,  0.0000],\n",
      "        [ 0.0000, 11.3963],\n",
      "        [ 0.0000,  6.0723],\n",
      "        [ 9.5655,  0.0000]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[7.1138, 0.0000],\n",
      "        [0.0000, 4.9818],\n",
      "        [0.3567, 0.0000],\n",
      "        [0.0000, 6.0554]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 7.4832],\n",
      "        [0.9340, 5.2451]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[4.2565, 0.0000],\n",
      "        [0.0000, 9.5519],\n",
      "        [0.0000, 3.0319],\n",
      "        [6.1111, 0.0000]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[ 0.0000, 12.0965],\n",
      "        [ 5.3980,  0.3762],\n",
      "        [10.1703,  0.0000],\n",
      "        [ 8.4209,  0.0000]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[1.6542, 0.0000],\n",
      "        [0.0000, 7.3474],\n",
      "        [0.0000, 0.3710],\n",
      "        [0.0000, 9.8371]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[7.3963, 0.0000],\n",
      "        [0.0000, 7.3235],\n",
      "        [8.7304, 4.6771],\n",
      "        [9.1491, 0.0000]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[7.6975, 0.0000],\n",
      "        [4.1282, 3.9309],\n",
      "        [7.0462, 0.0000],\n",
      "        [0.0000, 0.9784]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[5.8465, 0.0000],\n",
      "        [6.9547, 0.0000],\n",
      "        [0.0000, 1.2987],\n",
      "        [0.0000, 9.8384]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[10.5024,  0.0000],\n",
      "        [ 3.1246,  1.8864],\n",
      "        [ 0.0000,  5.8810],\n",
      "        [ 0.0000,  8.7733]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 8.5402],\n",
      "        [0.0000, 6.4038],\n",
      "        [0.0000, 1.9191],\n",
      "        [2.0694, 0.0000]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 5.2846],\n",
      "        [5.7606, 0.0000],\n",
      "        [0.0000, 3.7007],\n",
      "        [0.0000, 0.4347]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[ 0.0000,  1.6441],\n",
      "        [ 6.5218,  0.0000],\n",
      "        [ 8.1489,  1.5464],\n",
      "        [10.0859,  0.0000]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[ 0.0000, 10.3461],\n",
      "        [ 0.0000,  7.5865],\n",
      "        [ 4.8063,  0.0000],\n",
      "        [ 5.3107,  0.0000]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[ 3.3407,  0.0000],\n",
      "        [ 0.0000,  0.4704],\n",
      "        [ 6.5933,  0.0000],\n",
      "        [ 0.0000, 10.5536]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 4.7709],\n",
      "        [0.0000, 6.3053],\n",
      "        [5.9844, 0.0000],\n",
      "        [0.0000, 9.3723]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 5.3732],\n",
      "        [2.3459, 5.4462],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.9452, 6.6397]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 9.5106],\n",
      "        [0.3478, 0.0000],\n",
      "        [0.0000, 6.8914],\n",
      "        [0.0000, 7.8159]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0989, 6.0740],\n",
      "        [7.7969, 0.0000],\n",
      "        [4.5015, 0.5747],\n",
      "        [0.0000, 5.3963]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[11.4334,  0.0000],\n",
      "        [ 0.0000,  7.9724],\n",
      "        [ 7.2746,  0.0000],\n",
      "        [ 0.0000, 11.1968]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[6.1190, 0.0000],\n",
      "        [0.0000, 2.6608],\n",
      "        [0.0000, 5.3780],\n",
      "        [0.0000, 0.8663]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[ 8.4049,  0.0000],\n",
      "        [ 3.0573,  0.4817],\n",
      "        [ 0.0000,  4.5396],\n",
      "        [10.0862,  4.0629]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.9191, 4.3666],\n",
      "        [0.0000, 2.3686],\n",
      "        [6.5837, 0.0000],\n",
      "        [0.0000, 6.2653]], device='cuda:7', grad_fn=<ThresholdBackward0>)\n",
      "tensor([[139.,  14.],\n",
      "        [ 29., 170.]])\n",
      "tensor(309, device='cuda:7') 352\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_score=[]\n",
    "y_test=[]\n",
    "\n",
    "total_imgs=0;\n",
    "total_corrects=0\n",
    "u=0\n",
    "nb_classes=2\n",
    "confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "for i1,i2,label in validation_loader:\n",
    "\n",
    "\n",
    "    output=model_lstmXMLP(i1.to(device).float(),i2.to(device).float())\n",
    "    y_score.append(output)\n",
    "    y_test.append(label)\n",
    "    total_imgs=total_imgs+label.shape[0]\n",
    "    print(output)\n",
    "    z=torch.max(output,1)[1]==label.to(device)\n",
    "    _, preds = torch.max(output, 1)\n",
    "#         print(output.shape)\n",
    "\n",
    "    num_corrects=torch.sum(z)\n",
    "    total_corrects=total_corrects+num_corrects\n",
    "    for t, p in zip(label.view(-1), preds.view(-1)):\n",
    "        confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "\n",
    "    u=u+1\n",
    "\n",
    "\n",
    "print(confusion_matrix)\n",
    "print(total_corrects,total_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([352])\n",
      "torch.Size([352, 2])\n"
     ]
    }
   ],
   "source": [
    " \n",
    "print(torch.cat(y_test,0).shape)\n",
    "print(torch.cat(y_score,0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 yes\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc(torch.cat(y_test,0).numpy(),torch.cat(y_score,0).cpu().detach().numpy(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = pd.DataFrame({'fpr':azz['fpr'],'tpr':azz['tpr']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('prostrate_lstmXmlp_roc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
