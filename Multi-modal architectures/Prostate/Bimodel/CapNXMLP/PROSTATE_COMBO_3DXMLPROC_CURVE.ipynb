{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from path import Path\n",
    "import torch.utils.data as data\n",
    "from imageio import imread\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from PIL import *\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from path import Path\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "df=pd.DataFrame()\n",
    "azz={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(y_test,y_score,n_classes):\n",
    "    \n",
    "    \n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    lb = LabelBinarizer()\n",
    "    y_test=lb.fit_transform(y_test)\n",
    "    \n",
    "    y_test = np.hstack((1 - y_test, y_test))\n",
    "    \n",
    "#     y_test=lb.inverse_transform(y_test[:, 0])\n",
    "#     print(y_test.shape)\n",
    "#     print(y_test)    \n",
    "#     print(y_test[:, 0])\n",
    "#     print(y_score[:, 0])\n",
    "#     print(y_score[:, 1])\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    # Finally average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "    # Plot all ROC curves\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "             label='micro-average ROC curve (area = {0:0.2f})'\n",
    "                   ''.format(roc_auc[\"micro\"]),\n",
    "             color='deeppink', linestyle=':', linewidth=4)\n",
    "    azz['fpr']=fpr['macro']\n",
    "    azz['tpr']=tpr['macro']\n",
    "\n",
    "    plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "             label='macro-average ROC curve (area = {0:0.2f})'\n",
    "                   ''.format(roc_auc[\"macro\"]),\n",
    "             color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "    colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "    print(n_classes,\"yes\")\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        print(i)\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "                 label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                 ''.format(i, roc_auc[i]))\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('3D X MLP  FOR  PROSTATE  DATASET')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    ''' Scaled Dot-Product Attention '''\n",
    "    # given query, key,value it finds the rightful weighted component of v to get the attention applied ouput\n",
    "    #q,v,k- batch X length of sequence X features or encoding\n",
    "    #attention sholuld be -batchX7X7\n",
    "    def __init__(self, temperature, attn_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.dropout = nn.Dropout(attn_dropout)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "#         print(k.transpose(1,2).shape)\n",
    "\n",
    "        attn = torch.bmm(q, k.transpose(1, 2)) \n",
    "#         print(attn.shape)\n",
    "        attn = attn / self.temperature\n",
    "\n",
    "        if mask is not None:\n",
    "            attn = attn.masked_fill(mask, -np.inf)\n",
    "\n",
    "        attn = self.softmax(attn)\n",
    "        attn = self.dropout(attn)\n",
    "#         print(str(attn.shape)+\" \"+str(v.shape))\n",
    "        output = torch.bmm(attn, v)\n",
    "\n",
    "        return output, attn\n",
    "SDP=ScaledDotProductAttention(5)\n",
    "Ss=SDP(torch.zeros(5,6,100),torch.zeros(5,6,100),torch.zeros(5,6,100))\n",
    "# print(Ss[0].shape)\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    ''' Multi-Head Attention module '''\n",
    "\n",
    "    def __init__(self, n_head, d_model, d_k, d_v, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_head = n_head\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "\n",
    "        self.w_qs = nn.Linear(d_model, n_head * d_k)\n",
    "        self.w_ks = nn.Linear(d_model, n_head * d_k)\n",
    "        self.w_vs = nn.Linear(d_model, n_head * d_v)\n",
    "        nn.init.normal_(self.w_qs.weight, mean=0, std=np.sqrt(2.0 / (d_model + d_k)))\n",
    "        nn.init.normal_(self.w_ks.weight, mean=0, std=np.sqrt(2.0 / (d_model + d_k)))\n",
    "        nn.init.normal_(self.w_vs.weight, mean=0, std=np.sqrt(2.0 / (d_model + d_v)))\n",
    "\n",
    "        self.attention = ScaledDotProductAttention(temperature=np.power(d_k, 0.5))\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.fc = nn.Linear(n_head * d_v, d_model)\n",
    "        nn.init.xavier_normal_(self.fc.weight)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "\n",
    "        d_k, d_v, n_head = self.d_k, self.d_v, self.n_head\n",
    "\n",
    "        sz_b, len_q, _ = q.size()\n",
    "        sz_b, len_k, _ = k.size()\n",
    "        sz_b, len_v, _ = v.size()\n",
    "#         print(str(sz_b)+\"die\")\n",
    "\n",
    "        residual = q\n",
    "\n",
    "        q = self.w_qs(q).view(sz_b, len_q, n_head, d_k)\n",
    "        k = self.w_ks(k).view(sz_b, len_k, n_head, d_k)\n",
    "        v = self.w_vs(v).view(sz_b, len_v, n_head, d_v)\n",
    "\n",
    "        q = q.permute(2, 0, 1, 3).contiguous().view(-1, len_q, d_k) # (n*b) x lq x dk\n",
    "        k = k.permute(2, 0, 1, 3).contiguous().view(-1, len_k, d_k) # (n*b) x lk x dk\n",
    "        v = v.permute(2, 0, 1, 3).contiguous().view(-1, len_v, d_v) # (n*b) x lv x dv\n",
    "#         print(\"v-\"+str(v.shape))\n",
    "        if mask is not None:\n",
    "            mask = mask.repeat(n_head, 1, 1) # (n*b) x .. x ..\n",
    "        output, attn = self.attention(q, k, v, mask=mask)\n",
    "#         print(q.shape,k.shape,v.shape)\n",
    "        output = output.view(n_head, sz_b, len_q, d_v)\n",
    "        output = output.permute(1, 2, 0, 3).contiguous().view(sz_b, len_q, -1) # b x lq x (n*dv)\n",
    "\n",
    "        output = self.dropout(self.fc(output))\n",
    "        output = self.layer_norm(output + residual)\n",
    "\n",
    "        return output, attn\n",
    "MHA=MultiHeadAttention(4,15,15,15)\n",
    "op=MHA(torch.zeros(5,7,15),torch.zeros(5,7,15),torch.zeros(5,7,15))\n",
    "# print(op[0].shape)\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    ''' A two-feed-forward-layer module '''\n",
    "\n",
    "    def __init__(self, d_in, d_hid, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.w_1 = nn.Conv1d(d_in, d_hid, 1) # position-wise\n",
    "        self.w_2 = nn.Conv1d(d_hid, d_in, 1) # position-wise\n",
    "        self.layer_norm = nn.LayerNorm(d_in)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        output = x.transpose(1, 2)\n",
    "#         print(\"FCC-\"+str(output.shape))\n",
    "#         print(\"FFC_out-\"+str(self.w_1(output).shape))\n",
    "        output = self.w_2(F.relu(self.w_1(output)))\n",
    "        output = output.transpose(1, 2)\n",
    "        output = self.dropout(output)\n",
    "        output = self.layer_norm(output + residual)\n",
    "        return output\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    ''' Compose with two layers '''\n",
    "\n",
    "    def __init__(self, d_model, d_inner, n_head, d_k, d_v, dropout=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.slf_attn = MultiHeadAttention(\n",
    "            n_head, d_model, d_k, d_v, dropout=dropout)\n",
    "        self.pos_ffn = PositionwiseFeedForward(d_model, d_inner, dropout=dropout)\n",
    "\n",
    "    def forward(self, enc_input, non_pad_mask=None, slf_attn_mask=None):\n",
    "        enc_output, enc_slf_attn = self.slf_attn(\n",
    "            enc_input, enc_input, enc_input, mask=slf_attn_mask)\n",
    "#         print(\"ENC_o\")\n",
    "#         print(enc_output.shape)\n",
    "\n",
    "\n",
    "        enc_output = self.pos_ffn(enc_output)\n",
    "\n",
    "\n",
    "        return enc_output, enc_slf_attn\n",
    "    \n",
    "XX=EncoderLayer(15,10,4,10,10)\n",
    "\n",
    "zz=XX(torch.zeros(5,7,15))\n",
    "# print(\"ENc\")\n",
    "# print(zz[0].shape)\n",
    "# print(\"start\")\n",
    "class Encoder(nn.Module):\n",
    "    ''' A encoder model with self attention mechanism. '''\n",
    "\n",
    "    def __init__(self,n_modality,d_model,n_head,d_k,d_v,dropout,n_layers,d_inner=500):\n",
    "        #d_model - number of features in input 100 here\n",
    "        #n_head - number of heads of multihaded attention\n",
    "        #d_k=d_q=  number of features in query, key\n",
    "        #d_v = number of features in value whose weighted(attentioned) sum we gonna take\n",
    "        \n",
    "\n",
    "        super().__init__()\n",
    "        self.n_modality=n_modality\n",
    "#         self.stn=nn.ModuleList([SpatialTransformer(3, (240,240), 8) for _ in range(n_ref)])\n",
    "        \n",
    "        self.layer_stack = nn.ModuleList([EncoderLayer(d_model, d_inner, n_head, d_k, d_v, dropout=dropout) \n",
    "                                          for _ in range(n_layers)])\n",
    "        self.em=nn.Linear(32,100)\n",
    "        #self.em1=nn.Linear(225,100)\n",
    "        self.fc1=nn.Linear(d_model*n_modality,300)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.fc2=nn.Linear(300,100)\n",
    "        self.fc3=nn.Linear(100,2)\n",
    "#         self.fc4=nn.Linear(50,3)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=300)\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=100)\n",
    "        self.softmax=nn.Softmax(1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, embeddings1,embeddings2 ):\n",
    "\n",
    "\n",
    "        \n",
    "        encodings_total=[embeddings1,self.em(embeddings2)]\n",
    "\n",
    "        enc_output=torch.stack(encodings_total,0)\n",
    "\n",
    "        \n",
    "        enc_output=enc_output.permute(1,0,2)\n",
    "#         print(\"encoding_OUTPUT2-\"+str(enc_output.shape))\n",
    "\n",
    "        for enc_layer in self.layer_stack:\n",
    "            enc_output, enc_slf_attn = enc_layer(enc_output,non_pad_mask=None,slf_attn_mask=None)\n",
    "           \n",
    "        \n",
    "        final_input=enc_output.reshape(enc_output.shape[0],-1)\n",
    "\n",
    "        final=self.relu(self.fc3(self.bn2(self.relu((self.fc2(self.bn1(self.relu(self.fc1(final_input)))))))))\n",
    "        \n",
    "        return(final)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 100])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1=torch.zeros(4,100)\n",
    "e2=torch.zeros(4,100)\n",
    "e3=torch.stack([e1,e2],0)\n",
    "e3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_name</th>\n",
       "      <th>tag_0</th>\n",
       "      <th>tag_1</th>\n",
       "      <th>tag_2</th>\n",
       "      <th>tag_3</th>\n",
       "      <th>tag_4</th>\n",
       "      <th>tag_5</th>\n",
       "      <th>tag_6</th>\n",
       "      <th>tag_7</th>\n",
       "      <th>tag_8</th>\n",
       "      <th>...</th>\n",
       "      <th>tag_22</th>\n",
       "      <th>tag_23</th>\n",
       "      <th>tag_24</th>\n",
       "      <th>tag_25</th>\n",
       "      <th>tag_26</th>\n",
       "      <th>tag_27</th>\n",
       "      <th>tag_28</th>\n",
       "      <th>tag_29</th>\n",
       "      <th>tag_30</th>\n",
       "      <th>tag_31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhl</td>\n",
       "      <td>-0.004627</td>\n",
       "      <td>0.245317</td>\n",
       "      <td>0.004466</td>\n",
       "      <td>0.069272</td>\n",
       "      <td>-0.003327</td>\n",
       "      <td>-0.263032</td>\n",
       "      <td>-0.003749</td>\n",
       "      <td>0.251758</td>\n",
       "      <td>-0.003560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003328</td>\n",
       "      <td>-0.229637</td>\n",
       "      <td>0.004711</td>\n",
       "      <td>0.266983</td>\n",
       "      <td>-0.003079</td>\n",
       "      <td>0.228596</td>\n",
       "      <td>0.003680</td>\n",
       "      <td>-0.258568</td>\n",
       "      <td>-0.003935</td>\n",
       "      <td>0.195633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ndufa10</td>\n",
       "      <td>0.275199</td>\n",
       "      <td>0.009126</td>\n",
       "      <td>-0.289780</td>\n",
       "      <td>0.004290</td>\n",
       "      <td>0.173320</td>\n",
       "      <td>-0.012266</td>\n",
       "      <td>0.259847</td>\n",
       "      <td>0.010369</td>\n",
       "      <td>0.283457</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.258688</td>\n",
       "      <td>-0.011406</td>\n",
       "      <td>-0.293413</td>\n",
       "      <td>0.009331</td>\n",
       "      <td>0.251243</td>\n",
       "      <td>0.009058</td>\n",
       "      <td>-0.211729</td>\n",
       "      <td>-0.013103</td>\n",
       "      <td>0.264524</td>\n",
       "      <td>0.007954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ube4b</td>\n",
       "      <td>0.290513</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>-0.282832</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.173428</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>0.258021</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>0.284236</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.266636</td>\n",
       "      <td>-0.000551</td>\n",
       "      <td>-0.294954</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.244364</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>-0.203645</td>\n",
       "      <td>-0.000146</td>\n",
       "      <td>0.275976</td>\n",
       "      <td>0.000081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>foxo3</td>\n",
       "      <td>0.281134</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>-0.286166</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.173116</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>0.261762</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.288521</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.266013</td>\n",
       "      <td>-0.000130</td>\n",
       "      <td>-0.291289</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.253075</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>-0.203884</td>\n",
       "      <td>-0.000096</td>\n",
       "      <td>0.268459</td>\n",
       "      <td>-0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rap2a</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.245117</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>0.066403</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>-0.267965</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.249047</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000095</td>\n",
       "      <td>-0.223775</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.271736</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>0.235593</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>-0.267288</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.193028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  gene_name     tag_0     tag_1     tag_2     tag_3     tag_4     tag_5  \\\n",
       "0       vhl -0.004627  0.245317  0.004466  0.069272 -0.003327 -0.263032   \n",
       "1   ndufa10  0.275199  0.009126 -0.289780  0.004290  0.173320 -0.012266   \n",
       "2     ube4b  0.290513  0.000389 -0.282832  0.000397  0.173428 -0.000026   \n",
       "3     foxo3  0.281134  0.000155 -0.286166  0.000090  0.173116 -0.000050   \n",
       "4     rap2a  0.000149  0.245117 -0.000038  0.066403 -0.000030 -0.267965   \n",
       "\n",
       "      tag_6     tag_7     tag_8  ...    tag_22    tag_23    tag_24    tag_25  \\\n",
       "0 -0.003749  0.251758 -0.003560  ...  0.003328 -0.229637  0.004711  0.266983   \n",
       "1  0.259847  0.010369  0.283457  ... -0.258688 -0.011406 -0.293413  0.009331   \n",
       "2  0.258021 -0.000054  0.284236  ... -0.266636 -0.000551 -0.294954  0.000467   \n",
       "3  0.261762  0.000328  0.288521  ... -0.266013 -0.000130 -0.291289  0.000215   \n",
       "4 -0.000021  0.249047  0.000241  ... -0.000095 -0.223775  0.000131  0.271736   \n",
       "\n",
       "     tag_26    tag_27    tag_28    tag_29    tag_30    tag_31  \n",
       "0 -0.003079  0.228596  0.003680 -0.258568 -0.003935  0.195633  \n",
       "1  0.251243  0.009058 -0.211729 -0.013103  0.264524  0.007954  \n",
       "2  0.244364  0.000293 -0.203645 -0.000146  0.275976  0.000081  \n",
       "3  0.253075  0.000154 -0.203884 -0.000096  0.268459 -0.000015  \n",
       "4 -0.000234  0.235593  0.000200 -0.267288  0.000179  0.193028  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_set_MLP=pd.read_csv('Prostrate_MLP_features_ankit.csv')\n",
    "feature_set_3d=pd.read_csv('Ankitprostate_3d.csv')\n",
    "feature_set_3d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_name</th>\n",
       "      <th>tag_0</th>\n",
       "      <th>tag_1</th>\n",
       "      <th>tag_2</th>\n",
       "      <th>tag_3</th>\n",
       "      <th>tag_4</th>\n",
       "      <th>tag_5</th>\n",
       "      <th>tag_6</th>\n",
       "      <th>tag_7</th>\n",
       "      <th>tag_8</th>\n",
       "      <th>...</th>\n",
       "      <th>tag_90</th>\n",
       "      <th>tag_91</th>\n",
       "      <th>tag_92</th>\n",
       "      <th>tag_93</th>\n",
       "      <th>tag_94</th>\n",
       "      <th>tag_95</th>\n",
       "      <th>tag_96</th>\n",
       "      <th>tag_97</th>\n",
       "      <th>tag_98</th>\n",
       "      <th>tag_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhl</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.241405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.266189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smox</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.911898</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.720570</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>znf148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.678095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.640351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>map4k2</td>\n",
       "      <td>20.404165</td>\n",
       "      <td>23.852463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.247234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.033705</td>\n",
       "      <td>0.203660</td>\n",
       "      <td>56.684559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.108454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.755461</td>\n",
       "      <td>5.603198</td>\n",
       "      <td>13.697145</td>\n",
       "      <td>63.017044</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mapk4</td>\n",
       "      <td>42.203545</td>\n",
       "      <td>52.076824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>89.526337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.578827</td>\n",
       "      <td>10.026752</td>\n",
       "      <td>108.900192</td>\n",
       "      <td>...</td>\n",
       "      <td>3.838364</td>\n",
       "      <td>40.393089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.628872</td>\n",
       "      <td>18.609310</td>\n",
       "      <td>32.895622</td>\n",
       "      <td>120.597061</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  gene_name      tag_0      tag_1  tag_2      tag_3      tag_4  tag_5  \\\n",
       "0       vhl   0.000000   0.000000    0.0  22.241405   0.000000    0.0   \n",
       "1      smox   0.000000   0.000000    0.0   0.000000   0.000000    0.0   \n",
       "2    znf148   0.000000   0.000000    0.0  21.678095   0.000000    0.0   \n",
       "3    map4k2  20.404165  23.852463    0.0   0.000000  43.247234    0.0   \n",
       "4     mapk4  42.203545  52.076824    0.0   0.000000  89.526337    0.0   \n",
       "\n",
       "       tag_6      tag_7       tag_8  ...    tag_90     tag_91  tag_92  tag_93  \\\n",
       "0   0.000000   0.000000    0.000000  ...  0.000000   0.000000     0.0     0.0   \n",
       "1   0.000000   0.000000    7.911898  ...  0.000000   0.000000     0.0     0.0   \n",
       "2   0.000000   0.000000    0.000000  ...  0.000000   0.000000     0.0     0.0   \n",
       "3  31.033705   0.203660   56.684559  ...  0.000000  18.108454     0.0     0.0   \n",
       "4  67.578827  10.026752  108.900192  ...  3.838364  40.393089     0.0     0.0   \n",
       "\n",
       "   tag_94     tag_95     tag_96     tag_97      tag_98     tag_99  \n",
       "0     0.0   0.000000   0.000000   0.000000    0.000000  10.266189  \n",
       "1     0.0   0.000000   0.000000   0.000000   12.720570   0.000000  \n",
       "2     0.0   0.000000   0.000000   0.000000    0.000000  10.640351  \n",
       "3     0.0  28.755461   5.603198  13.697145   63.017044   0.000000  \n",
       "4     0.0  57.628872  18.609310  32.895622  120.597061   0.000000  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_set_MLP.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2424, 100)\n",
      "2424\n"
     ]
    }
   ],
   "source": [
    "header_of_MLP=['tag_'+str(i) for i in range(feature_set_MLP.shape[1]-1)]\n",
    "features_MLP=np.array(feature_set_MLP[header_of_MLP])\n",
    "gene_MLP=feature_set_MLP['gene_name']\n",
    "print(features_MLP.shape)\n",
    "print(len(gene_MLP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_MLP={}\n",
    "u=0\n",
    "for gn in gene_MLP:\n",
    "    dictionary_MLP[gn]=features_MLP[u]\n",
    "    u=u+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(723, 32)\n",
      "723\n"
     ]
    }
   ],
   "source": [
    "header_of_3d=['tag_'+str(i) for i in range(feature_set_3d.shape[1]-1)]\n",
    "features_3d=np.array(feature_set_3d[header_of_3d])\n",
    "gene_3d=feature_set_3d['gene_name']\n",
    "print(features_3d.shape)\n",
    "print(len(gene_3d))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "723\n"
     ]
    }
   ],
   "source": [
    "dictionary_3d={}\n",
    "u=f=0\n",
    "for gn in gene_3d:\n",
    "    if gn in dictionary_3d.keys():\n",
    "#         print(gn)\n",
    "        f=f+1\n",
    "    dictionary_3d[gn]=features_3d[u]\n",
    "    u=u+1\n",
    "print(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "676\n"
     ]
    }
   ],
   "source": [
    "print(len(dictionary_3d.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2424,)\n"
     ]
    }
   ],
   "source": [
    "fil=open('../../Multi-modality/Model/Prostrate/uni model/MLP/Labels_prostate.txt','r')\n",
    "tmp=list()\n",
    "for line in fil:\n",
    "\ttmp.append(int(line))\n",
    "\n",
    "label_PROSTRATE=np.array(tmp)\n",
    "print(label_PROSTRATE.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309 414 0\n"
     ]
    }
   ],
   "source": [
    "class Sequenceloader(data.Dataset):\n",
    "    def __init__(self,GN,Feat,label):\n",
    "        self.gene_names=GN\n",
    "        self.features_mlp=Feat\n",
    "        self.label=label\n",
    "        self.coincdgene_name=[]\n",
    "        self.coincidfeature_MLP=[]\n",
    "        self.coincidfeature_3d=[]\n",
    "        self.coincidlabel=[]\n",
    "        for i in range(len(self.gene_names)):\n",
    "            u=self.gene_names[i]\n",
    "            if u in dictionary_3d.keys():\n",
    "                \n",
    "                if np.array(self.label[i])==1:\n",
    "                    ch=1\n",
    "                else:\n",
    "                    ch=1\n",
    "                    \n",
    "                for jj in range(ch):\n",
    "                    self.coincdgene_name.append(u)\n",
    "                    self.coincidfeature_MLP.append(self.features_mlp[i])\n",
    "                    self.coincidfeature_3d.append(dictionary_3d[u])\n",
    "                    self.coincidlabel.append(self.label[i])\n",
    "        \n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "#         print(len(self.dataset))\n",
    "        return len(self.coincdgene_name)       \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "         return np.array(self.coincidfeature_MLP[index]),np.array(self.coincidfeature_3d[index]),np.array(self.coincidlabel[index])\n",
    "#         print(self.dataset['gen_name'][index])          \n",
    "#         try:\n",
    "           \n",
    "#         except :\n",
    "            \n",
    "total_set=Sequenceloader(gene_MLP,features_MLP,label_PROSTRATE)  \n",
    "a=b=c=0\n",
    "for x,y,z in total_set:\n",
    "    if(z==0):\n",
    "        a=a+1\n",
    "    elif z==1:\n",
    "        b=b+1\n",
    "    else:\n",
    "        c=c+1\n",
    "print(a,b,c)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(total_set)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(total_set, batch_size=batch_size, \n",
    "                                           sampler=train_sampler,drop_last=True)\n",
    "validation_loader = torch.utils.data.DataLoader(total_set, batch_size=batch_size,\n",
    "                                                sampler=valid_sampler,drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n",
      "torch.Size([4, 100]) torch.Size([4, 32]) torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "for a,b,c in train_loader:\n",
    "    print(a.shape,b.shape,c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun 25 13:56:29 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 384.111                Driver Version: 384.111                   |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:04:00.0  On |                  N/A |\n",
      "|  0%   31C    P8    18W / 250W |   2083MiB / 11172MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 24%   44C    P2    56W / 250W |   4630MiB / 11172MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce GTX 108...  Off  | 00000000:08:00.0 Off |                  N/A |\n",
      "|  0%   56C    P2    61W / 250W |   8974MiB / 11172MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce GTX 108...  Off  | 00000000:0A:00.0 Off |                  N/A |\n",
      "| 23%   40C    P2    55W / 250W |   1931MiB / 11172MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce GTX 108...  Off  | 00000000:85:00.0 Off |                  N/A |\n",
      "| 66%   78C    P2   175W / 250W |   2011MiB / 11172MiB |     71%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce GTX 108...  Off  | 00000000:86:00.0 Off |                  N/A |\n",
      "| 34%   58C    P2    59W / 250W |  10786MiB / 11172MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce GTX 108...  Off  | 00000000:89:00.0 Off |                  N/A |\n",
      "| 23%   31C    P2    53W / 250W |   1152MiB / 11172MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce GTX 108...  Off  | 00000000:8A:00.0 Off |                  N/A |\n",
      "|  0%   37C    P8    18W / 250W |   1480MiB / 11172MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      5857      G   /usr/lib/xorg/Xorg                            50MiB |\n",
      "|    0     41672      C   ...ratik/anaconda2/envs/kaiser/bin/python3  1803MiB |\n",
      "|    0     44049      C   python                                       215MiB |\n",
      "|    1     20349      C   python3                                      485MiB |\n",
      "|    1     28135      C   python3                                      483MiB |\n",
      "|    1     41672      C   ...ratik/anaconda2/envs/kaiser/bin/python3  1673MiB |\n",
      "|    1     41685      C   python3                                      497MiB |\n",
      "|    1     43861      C   python3                                      497MiB |\n",
      "|    1     44323      C   python3                                      485MiB |\n",
      "|    1     48626      C   python3                                      497MiB |\n",
      "|    2     34026      C   python                                      8963MiB |\n",
      "|    3     13670      C   python                                       225MiB |\n",
      "|    3     31976      C   python                                       483MiB |\n",
      "|    3     33776      C   ...kamalpcs17/anaconda3_sockeye/bin/python   995MiB |\n",
      "|    3     34026      C   python                                       215MiB |\n",
      "|    4     21972      C   python                                      1785MiB |\n",
      "|    4     34026      C   python                                       215MiB |\n",
      "|    5     44049      C   python                                     10775MiB |\n",
      "|    6      2266      C   /home1/sriparna/anaconda3/bin/python         709MiB |\n",
      "|    6     34026      C   python                                       215MiB |\n",
      "|    6     44049      C   python                                       215MiB |\n",
      "|    7     34026      C   python                                       215MiB |\n",
      "|    7     41672      C   ...ratik/anaconda2/envs/kaiser/bin/python3  1037MiB |\n",
      "|    7     44049      C   python                                       215MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device='cpu'\n",
    "model_3dXMLP=Encoder(2,100,4,300,300,True,4).to(device)\n",
    "uz=torch.rand(4,32).to(device)\n",
    "vz=torch.rand(4,100).to(device)\n",
    "model_3dXMLP(vz,uz).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_3dXMLP.load_state_dict(torch.load(Path('1ANKIT_prostateCOMBO_3DXMLP.pt'),map_location='cpu'))\n",
    "optim_params = [\n",
    "    {'params': model_3dXMLP.parameters(), 'lr': 0.0001}\n",
    "]\n",
    "optimizer = torch.optim.Adam(optim_params)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 9.3312],\n",
      "        [1.0793, 0.0000],\n",
      "        [6.0432, 0.0000],\n",
      "        [1.0130, 0.0000]], grad_fn=<ThresholdBackward0>)\n",
      "tensor([[ 0.0000, 12.2542],\n",
      "        [ 2.1763,  0.0000],\n",
      "        [ 7.9347,  0.0000],\n",
      "        [ 0.0000,  9.5075]], grad_fn=<ThresholdBackward0>)\n",
      "tensor([[ 0.0000, 12.0322],\n",
      "        [ 0.0000,  5.7469],\n",
      "        [ 4.3608,  0.0000],\n",
      "        [ 0.0000,  2.9600]], grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 0.0000],\n",
      "        [0.0000, 6.8742],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 4.1467]], grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 7.3775],\n",
      "        [0.0000, 4.2454],\n",
      "        [6.4386, 0.0000],\n",
      "        [8.6354, 0.0000]], grad_fn=<ThresholdBackward0>)\n",
      "tensor([[ 0.0000,  8.2082],\n",
      "        [ 1.7984,  0.0000],\n",
      "        [ 9.6097,  0.0000],\n",
      "        [ 0.0000, 10.3834]], grad_fn=<ThresholdBackward0>)\n",
      "tensor([[ 0.0000, 11.0783],\n",
      "        [10.1827,  0.0000],\n",
      "        [ 4.4600,  0.0000],\n",
      "        [ 0.2014,  0.0000]], grad_fn=<ThresholdBackward0>)\n",
      "tensor([[ 0.0000, 10.0250],\n",
      "        [ 0.0000,  8.2206],\n",
      "        [ 8.6670,  0.0000],\n",
      "        [10.6280,  0.0000]], grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 5.5709],\n",
      "        [6.3148, 0.0000],\n",
      "        [0.0000, 9.5269],\n",
      "        [0.7862, 0.0000]], grad_fn=<ThresholdBackward0>)\n",
      "tensor([[ 0.0000,  0.0000],\n",
      "        [ 0.0000,  9.5330],\n",
      "        [ 6.1077,  0.0000],\n",
      "        [ 0.0000, 10.6175]], grad_fn=<ThresholdBackward0>)\n",
      "tensor([[ 2.5780,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [10.9197,  3.7704],\n",
      "        [ 0.0000,  5.0116]], grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 0.0000],\n",
      "        [0.0000, 7.9156],\n",
      "        [1.6841, 9.8685],\n",
      "        [0.0000, 4.6975]], grad_fn=<ThresholdBackward0>)\n",
      "tensor([[ 7.3839,  0.0000],\n",
      "        [11.4399,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000, 12.9318]], grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 1.3399],\n",
      "        [9.5531, 0.0000],\n",
      "        [3.9187, 0.0000],\n",
      "        [0.0000, 3.1427]], grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 1.1617],\n",
      "        [8.6227, 0.0000],\n",
      "        [0.0000, 4.3778],\n",
      "        [0.0000, 8.4543]], grad_fn=<ThresholdBackward0>)\n",
      "tensor([[12.4271,  0.0000],\n",
      "        [ 0.0000,  8.2213],\n",
      "        [ 0.0000,  3.2107],\n",
      "        [ 0.0000,  8.9725]], grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 4.3445],\n",
      "        [0.0000, 6.1336],\n",
      "        [0.8583, 0.0000],\n",
      "        [0.0000, 0.2733]], grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 4.4371],\n",
      "        [0.0000, 0.4262],\n",
      "        [7.0714, 0.0000],\n",
      "        [0.0000, 4.0383]], grad_fn=<ThresholdBackward0>)\n",
      "tensor([[8.1222, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 4.9757],\n",
      "        [4.7967, 0.0000]], grad_fn=<ThresholdBackward0>)\n",
      "tensor([[ 0.0000, 11.5901],\n",
      "        [ 0.0000,  4.2925],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 6.6382,  0.0000]], grad_fn=<ThresholdBackward0>)\n",
      "tensor([[ 0.0000, 12.2513],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 5.3071,  1.2902],\n",
      "        [10.1271,  0.0000]], grad_fn=<ThresholdBackward0>)\n",
      "tensor([[ 1.8391,  0.0000],\n",
      "        [ 4.0353,  0.0000],\n",
      "        [ 8.7003,  0.0000],\n",
      "        [ 0.0000, 11.2840]], grad_fn=<ThresholdBackward0>)\n",
      "tensor([[ 0.0000,  0.0000],\n",
      "        [10.8840,  0.0000],\n",
      "        [ 0.0000,  3.5059],\n",
      "        [ 0.0000,  8.0726]], grad_fn=<ThresholdBackward0>)\n",
      "tensor([[ 0.0000,  0.0000],\n",
      "        [ 0.6686, 10.6865],\n",
      "        [ 0.0000,  6.4847],\n",
      "        [ 0.0000,  6.3850]], grad_fn=<ThresholdBackward0>)\n",
      "tensor([[5.8984, 0.0000],\n",
      "        [7.6846, 3.5544],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000]], grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [8.1424, 0.0000],\n",
      "        [5.5886, 1.5697]], grad_fn=<ThresholdBackward0>)\n",
      "tensor([[2.1343, 0.0000],\n",
      "        [0.0000, 2.5792],\n",
      "        [4.9480, 0.0000],\n",
      "        [0.0000, 6.0219]], grad_fn=<ThresholdBackward0>)\n",
      "tensor([[ 0.0000,  6.4861],\n",
      "        [10.0755,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 3.9095,  0.0000]], grad_fn=<ThresholdBackward0>)\n",
      "tensor([[5.4168, 0.0000],\n",
      "        [0.0000, 9.8152],\n",
      "        [0.0000, 0.0000],\n",
      "        [7.5389, 0.0000]], grad_fn=<ThresholdBackward0>)\n",
      "tensor([[4.6653, 0.0000],\n",
      "        [0.0000, 8.6454],\n",
      "        [7.0303, 0.0000],\n",
      "        [0.0000, 7.7096]], grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 2.8383],\n",
      "        [0.7170, 1.9960],\n",
      "        [5.5528, 0.0000],\n",
      "        [0.0000, 6.3455]], grad_fn=<ThresholdBackward0>)\n",
      "tensor([[ 0.0000,  9.0374],\n",
      "        [10.4714,  0.3517],\n",
      "        [ 4.1385,  0.0000],\n",
      "        [ 0.0000,  0.0000]], grad_fn=<ThresholdBackward0>)\n",
      "tensor([[ 0.0000,  0.0000],\n",
      "        [ 0.0000,  7.8988],\n",
      "        [ 5.4801,  7.4737],\n",
      "        [ 0.0000, 10.8927]], grad_fn=<ThresholdBackward0>)\n",
      "tensor([[0.0000, 7.8605],\n",
      "        [0.0000, 9.8133],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 5.7318]], grad_fn=<ThresholdBackward0>)\n",
      "tensor([[ 0.0000,  3.8308],\n",
      "        [ 0.4169,  8.0482],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000, 10.8410]], grad_fn=<ThresholdBackward0>)\n",
      "tensor([[ 8.0423,  0.0000],\n",
      "        [ 0.0000,  4.7455],\n",
      "        [ 0.0000, 11.2857],\n",
      "        [ 8.5442,  0.0000]], grad_fn=<ThresholdBackward0>)\n",
      "tensor([[48., 15.],\n",
      "        [ 6., 75.]])\n",
      "tensor(123) 144\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_score=[]\n",
    "y_test=[]\n",
    "\n",
    "total_imgs=0;\n",
    "total_corrects=0\n",
    "u=0\n",
    "nb_classes=2\n",
    "confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "for i1,i2,label in validation_loader:\n",
    "\n",
    "\n",
    "    output=model_3dXMLP(i1.to(device).float(),i2.to(device).float())\n",
    "    y_score.append(output)\n",
    "    y_test.append(label)\n",
    "    total_imgs=total_imgs+label.shape[0]\n",
    "    print(output)\n",
    "    z=torch.max(output,1)[1]==label.to(device)\n",
    "    _, preds = torch.max(output, 1)\n",
    "#         print(output.shape)\n",
    "\n",
    "    num_corrects=torch.sum(z)\n",
    "    total_corrects=total_corrects+num_corrects\n",
    "    for t, p in zip(label.view(-1), preds.view(-1)):\n",
    "        confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "\n",
    "    u=u+1\n",
    "\n",
    "\n",
    "print(confusion_matrix)\n",
    "print(total_corrects,total_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 yes\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc(torch.cat(y_test,0).numpy(),torch.cat(y_score,0).cpu().detach().numpy(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = pd.DataFrame({'fpr':azz['fpr'],'tpr':azz['tpr']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('prostrate_3dXmlp_roc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
