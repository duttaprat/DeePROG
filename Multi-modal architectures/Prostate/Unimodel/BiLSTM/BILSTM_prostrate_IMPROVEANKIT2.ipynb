{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1.post2\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from os import path\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "from torchvision import datasets, transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from path import Path\n",
    "import torch.utils.data as data\n",
    "\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "import os\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "all_letters=\"ACTG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def letterToIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "def letterToTensor(letter):\n",
    "  tensor=torch.zeros(1,4)\n",
    "  tensor[0][letterToIndex(letter)] = 1\n",
    "  return tensor\n",
    "def lineToTensor(line):\n",
    "  tensor=torch.zeros(len(line),1,4)\n",
    "  for li,letters in enumerate(line):\n",
    "    tensor[li][0][letterToIndex(letters)]=1\n",
    "  return(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm = nn.LSTM(input_size=4,hidden_size=100)  \n",
    "# lstm=lstm.to(device)\n",
    "# fc=nn.Linear(100,3).to(device)\n",
    "# learning_rate = 0.05\n",
    "# criterion = nn.NLLLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2424"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "File_object = open('Labels_prostate.txt',\"r\")\n",
    "label_txt=File_object.readlines()\n",
    "\n",
    " \n",
    "len(label_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2424"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "\n",
    "genename=pd.read_csv('preprocessed_prostrate.csv')\n",
    "u=genename['gen_name']\n",
    "\n",
    "mapz=pd.read_csv('sequence.csv')\n",
    "len(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "key=mapz['gene'].tolist()\n",
    "sequence=mapz['sequence'].tolist()\n",
    "\n",
    "dictionary = dict(zip(key, sequence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2424"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gene_preprocessing(text):\n",
    "  g=\"\"\n",
    "  u=0\n",
    "  for i in text:\n",
    "    if  ord(i)<=90 and ord(i)>=65:\n",
    "      g=g+i.lower()\n",
    "    else:\n",
    "      g=g+i\n",
    "  return(g)\n",
    "len(genename['gen_name'])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2424/2424 [00:03<00:00, 813.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "787 976 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss_epoch=0\n",
    "a=0\n",
    "b=0\n",
    "c=0\n",
    "d=0\n",
    "mint=99999999999999\n",
    "maxt=-1\n",
    "total_gene=[]\n",
    "total_label=[]\n",
    "for V in tqdm.tqdm(range(len(genename['gen_name']))):\n",
    "    j=genename['gen_name'][V]\n",
    "    GN=gene_preprocessing(j)\n",
    "    #print(GN)\n",
    "    lab=int(label_txt[V].replace('\\n',''))\n",
    "    #print(lab)\n",
    "    if GN not in dictionary.keys():\n",
    "\n",
    "        continue\n",
    "#     print(GN)\n",
    "    lin2TenGene=np.array(lineToTensor(dictionary[GN][:70]))\n",
    "    if(lab==0):\n",
    "#         if a>1000:\n",
    "#             continue\n",
    "        a=a+1\n",
    "    elif lab==1:\n",
    "#         if b>1000:\n",
    "#             continue\n",
    "        b=b+1\n",
    "#     elif(lab==2):\n",
    "# #         if c>1000:\n",
    "# #             continue\n",
    "#         c=c+1\n",
    "#         total_gene.append(lin2TenGene)\n",
    "#         total_label.append(lab)\n",
    "#         total_gene.append(lin2TenGene)\n",
    "#         total_label.append(lab)\n",
    "\n",
    "    total_gene.append(lin2TenGene)\n",
    "    cc=lineToTensor(dictionary[GN][:70])\n",
    "#     print(cc)\n",
    "#     print(cc[:,0,:].shape)\n",
    "    total_label.append(lab)\n",
    "    \n",
    "    \n",
    "print(a,b,c,d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2424/2424 [00:01<00:00, 1683.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "976 976 0 0\n",
      "50 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for V in tqdm.tqdm(range(len(genename['gen_name']))):\n",
    "    j=genename['gen_name'][V]\n",
    "    GN=gene_preprocessing(j)\n",
    "    #print(GN)\n",
    "    lab=int(label_txt[V].replace('\\n',''))\n",
    "    #print(lab)\n",
    "    if GN not in dictionary.keys():\n",
    "\n",
    "        continue\n",
    "    mint=min (len(dictionary[GN][:50]),mint)\n",
    "    maxt=max (len(dictionary[GN][:50]),maxt)\n",
    "#     print(GN)\n",
    "    lin2TenGene=np.array(lineToTensor(dictionary[GN][:70]))\n",
    "    if(lab==0):\n",
    "        \n",
    "        if a>975:\n",
    "            continue\n",
    "        else:\n",
    "            total_gene.append(lin2TenGene)\n",
    "            total_label.append(lab)\n",
    "            \n",
    "            a=a+1\n",
    "    elif lab==1:\n",
    "        continue\n",
    "\n",
    "\n",
    "    \n",
    "print(a,b,c,d)\n",
    "print(mint,maxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1952\n",
      "1952\n"
     ]
    }
   ],
   "source": [
    "print(len(total_gene))\n",
    "print(len(total_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(70, 1, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'gen_name':total_gene,'gen_label':total_label})\n",
    "df.to_csv('Prostrate_LSTM_traintest.csv')\n",
    "print(len(df))        \n",
    "df['gen_name'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1952\n",
      "0\n",
      "yes\n",
      "1\n",
      "yes\n",
      "2\n",
      "yes\n",
      "3\n",
      "yes\n",
      "4\n",
      "yes\n",
      "5\n",
      "yes\n",
      "6\n",
      "yes\n",
      "7\n",
      "yes\n",
      "8\n",
      "yes\n",
      "9\n",
      "yes\n",
      "10\n",
      "yes\n",
      "11\n",
      "yes\n",
      "12\n",
      "yes\n",
      "13\n",
      "yes\n",
      "14\n",
      "yes\n",
      "15\n",
      "yes\n",
      "16\n",
      "yes\n",
      "17\n",
      "yes\n",
      "18\n",
      "yes\n",
      "19\n",
      "yes\n",
      "20\n",
      "yes\n",
      "21\n",
      "yes\n",
      "22\n",
      "yes\n",
      "23\n",
      "yes\n",
      "24\n",
      "yes\n",
      "25\n",
      "yes\n",
      "26\n",
      "yes\n",
      "27\n",
      "yes\n",
      "28\n",
      "yes\n",
      "29\n",
      "yes\n",
      "30\n",
      "yes\n",
      "31\n",
      "yes\n",
      "32\n",
      "yes\n",
      "33\n",
      "yes\n",
      "34\n",
      "yes\n",
      "35\n",
      "yes\n",
      "36\n",
      "yes\n",
      "37\n",
      "yes\n",
      "38\n",
      "yes\n",
      "39\n",
      "yes\n",
      "40\n",
      "yes\n",
      "41\n",
      "yes\n",
      "42\n",
      "yes\n",
      "43\n",
      "yes\n",
      "44\n",
      "yes\n",
      "45\n",
      "yes\n",
      "46\n",
      "yes\n",
      "47\n",
      "yes\n",
      "48\n",
      "yes\n",
      "49\n",
      "yes\n",
      "50\n",
      "yes\n",
      "51\n",
      "yes\n",
      "52\n",
      "yes\n",
      "53\n",
      "yes\n",
      "54\n",
      "yes\n",
      "55\n",
      "yes\n",
      "56\n",
      "yes\n",
      "57\n",
      "yes\n",
      "58\n",
      "yes\n",
      "59\n",
      "yes\n",
      "60\n",
      "yes\n",
      "61\n",
      "yes\n",
      "62\n",
      "yes\n",
      "63\n",
      "yes\n",
      "64\n",
      "yes\n",
      "65\n",
      "yes\n",
      "66\n",
      "yes\n",
      "67\n",
      "yes\n",
      "68\n",
      "yes\n",
      "69\n",
      "yes\n",
      "70\n",
      "yes\n",
      "71\n",
      "yes\n",
      "72\n",
      "yes\n",
      "73\n",
      "yes\n",
      "74\n",
      "yes\n",
      "75\n",
      "yes\n",
      "76\n",
      "yes\n",
      "77\n",
      "yes\n",
      "78\n",
      "yes\n",
      "79\n",
      "yes\n",
      "80\n",
      "yes\n",
      "81\n",
      "yes\n",
      "82\n",
      "yes\n",
      "83\n",
      "yes\n",
      "84\n",
      "yes\n",
      "85\n",
      "yes\n",
      "86\n",
      "yes\n",
      "87\n",
      "yes\n",
      "88\n",
      "yes\n",
      "89\n",
      "yes\n",
      "90\n",
      "yes\n",
      "91\n",
      "yes\n",
      "92\n",
      "yes\n",
      "93\n",
      "yes\n",
      "94\n",
      "yes\n",
      "95\n",
      "yes\n",
      "96\n",
      "yes\n",
      "97\n",
      "yes\n",
      "98\n",
      "yes\n",
      "99\n",
      "yes\n",
      "100\n",
      "yes\n",
      "101\n",
      "yes\n",
      "102\n",
      "yes\n",
      "103\n",
      "yes\n",
      "104\n",
      "yes\n",
      "105\n",
      "yes\n",
      "106\n",
      "yes\n",
      "107\n",
      "yes\n",
      "108\n",
      "yes\n",
      "109\n",
      "yes\n",
      "110\n",
      "yes\n",
      "111\n",
      "yes\n",
      "112\n",
      "yes\n",
      "113\n",
      "yes\n",
      "114\n",
      "yes\n",
      "115\n",
      "yes\n",
      "116\n",
      "yes\n",
      "117\n",
      "yes\n",
      "118\n",
      "yes\n",
      "119\n",
      "yes\n",
      "120\n",
      "yes\n",
      "121\n",
      "yes\n",
      "122\n",
      "yes\n",
      "123\n",
      "yes\n",
      "124\n",
      "yes\n",
      "125\n",
      "yes\n",
      "126\n",
      "yes\n",
      "127\n",
      "yes\n",
      "128\n",
      "yes\n",
      "129\n",
      "yes\n",
      "130\n",
      "yes\n",
      "131\n",
      "yes\n",
      "132\n",
      "yes\n",
      "133\n",
      "yes\n",
      "134\n",
      "yes\n",
      "135\n",
      "yes\n",
      "136\n",
      "yes\n",
      "137\n",
      "yes\n",
      "138\n",
      "yes\n",
      "139\n",
      "yes\n",
      "140\n",
      "yes\n",
      "141\n",
      "yes\n",
      "142\n",
      "yes\n",
      "143\n",
      "yes\n",
      "144\n",
      "yes\n",
      "145\n",
      "yes\n",
      "146\n",
      "yes\n",
      "147\n",
      "yes\n",
      "148\n",
      "yes\n",
      "149\n",
      "yes\n",
      "150\n",
      "yes\n",
      "151\n",
      "yes\n",
      "152\n",
      "yes\n",
      "153\n",
      "yes\n",
      "154\n",
      "yes\n",
      "155\n",
      "yes\n",
      "156\n",
      "yes\n",
      "157\n",
      "yes\n",
      "158\n",
      "yes\n",
      "159\n",
      "yes\n",
      "160\n",
      "yes\n",
      "161\n",
      "yes\n",
      "162\n",
      "yes\n",
      "163\n",
      "yes\n",
      "164\n",
      "yes\n",
      "165\n",
      "yes\n",
      "166\n",
      "yes\n",
      "167\n",
      "yes\n",
      "168\n",
      "yes\n",
      "169\n",
      "yes\n",
      "170\n",
      "yes\n",
      "171\n",
      "yes\n",
      "172\n",
      "yes\n",
      "173\n",
      "yes\n",
      "174\n",
      "yes\n",
      "175\n",
      "yes\n",
      "176\n",
      "yes\n",
      "177\n",
      "yes\n",
      "178\n",
      "yes\n",
      "179\n",
      "yes\n",
      "180\n",
      "yes\n",
      "181\n",
      "yes\n",
      "182\n",
      "yes\n",
      "183\n",
      "yes\n",
      "184\n",
      "yes\n",
      "185\n",
      "yes\n",
      "186\n",
      "yes\n",
      "187\n",
      "yes\n",
      "188\n",
      "yes\n",
      "189\n",
      "yes\n",
      "190\n",
      "yes\n",
      "191\n",
      "yes\n",
      "192\n",
      "yes\n",
      "193\n",
      "yes\n",
      "194\n",
      "yes\n",
      "195\n",
      "yes\n",
      "196\n",
      "yes\n",
      "197\n",
      "yes\n",
      "198\n",
      "yes\n",
      "199\n",
      "yes\n",
      "200\n",
      "yes\n",
      "201\n",
      "yes\n",
      "202\n",
      "yes\n",
      "203\n",
      "yes\n",
      "204\n",
      "yes\n",
      "205\n",
      "yes\n",
      "206\n",
      "yes\n",
      "207\n",
      "yes\n",
      "208\n",
      "yes\n",
      "209\n",
      "yes\n",
      "210\n",
      "yes\n",
      "211\n",
      "yes\n",
      "212\n",
      "yes\n",
      "213\n",
      "yes\n",
      "214\n",
      "yes\n",
      "215\n",
      "yes\n",
      "216\n",
      "yes\n",
      "217\n",
      "yes\n",
      "218\n",
      "yes\n",
      "219\n",
      "yes\n",
      "220\n",
      "yes\n",
      "221\n",
      "yes\n",
      "222\n",
      "yes\n",
      "223\n",
      "yes\n",
      "224\n",
      "yes\n",
      "225\n",
      "yes\n",
      "226\n",
      "yes\n",
      "227\n",
      "yes\n",
      "228\n",
      "yes\n",
      "229\n",
      "yes\n",
      "230\n",
      "yes\n",
      "231\n",
      "yes\n",
      "232\n",
      "yes\n",
      "233\n",
      "yes\n",
      "234\n",
      "yes\n",
      "235\n",
      "yes\n",
      "236\n",
      "yes\n",
      "237\n",
      "yes\n",
      "238\n",
      "yes\n",
      "239\n",
      "yes\n",
      "240\n",
      "yes\n",
      "241\n",
      "yes\n",
      "242\n",
      "yes\n",
      "243\n",
      "yes\n",
      "244\n",
      "yes\n",
      "245\n",
      "yes\n",
      "246\n",
      "yes\n",
      "247\n",
      "yes\n",
      "248\n",
      "yes\n",
      "249\n",
      "yes\n",
      "250\n",
      "yes\n",
      "251\n",
      "yes\n",
      "252\n",
      "yes\n",
      "253\n",
      "yes\n",
      "254\n",
      "yes\n",
      "255\n",
      "yes\n",
      "256\n",
      "yes\n",
      "257\n",
      "yes\n",
      "258\n",
      "yes\n",
      "259\n",
      "yes\n",
      "260\n",
      "yes\n",
      "261\n",
      "yes\n",
      "262\n",
      "yes\n",
      "263\n",
      "yes\n",
      "264\n",
      "yes\n",
      "265\n",
      "yes\n",
      "266\n",
      "yes\n",
      "267\n",
      "yes\n",
      "268\n",
      "yes\n",
      "269\n",
      "yes\n",
      "270\n",
      "yes\n",
      "271\n",
      "yes\n",
      "272\n",
      "yes\n",
      "273\n",
      "yes\n",
      "274\n",
      "yes\n",
      "275\n",
      "yes\n",
      "276\n",
      "yes\n",
      "277\n",
      "yes\n",
      "278\n",
      "yes\n",
      "279\n",
      "yes\n",
      "280\n",
      "yes\n",
      "281\n",
      "yes\n",
      "282\n",
      "yes\n",
      "283\n",
      "yes\n",
      "284\n",
      "yes\n",
      "285\n",
      "yes\n",
      "286\n",
      "yes\n",
      "287\n",
      "yes\n",
      "288\n",
      "yes\n",
      "289\n",
      "yes\n",
      "290\n",
      "yes\n",
      "291\n",
      "yes\n",
      "292\n",
      "yes\n",
      "293\n",
      "yes\n",
      "294\n",
      "yes\n",
      "295\n",
      "yes\n",
      "296\n",
      "yes\n",
      "297\n",
      "yes\n",
      "298\n",
      "yes\n",
      "299\n",
      "yes\n",
      "300\n",
      "yes\n",
      "301\n",
      "yes\n",
      "302\n",
      "yes\n",
      "303\n",
      "yes\n",
      "304\n",
      "yes\n",
      "305\n",
      "yes\n",
      "306\n",
      "yes\n",
      "307\n",
      "yes\n",
      "308\n",
      "yes\n",
      "309\n",
      "yes\n",
      "310\n",
      "yes\n",
      "311\n",
      "yes\n",
      "312\n",
      "yes\n",
      "313\n",
      "yes\n",
      "314\n",
      "yes\n",
      "315\n",
      "yes\n",
      "316\n",
      "yes\n",
      "317\n",
      "yes\n",
      "318\n",
      "yes\n",
      "319\n",
      "yes\n",
      "320\n",
      "yes\n",
      "321\n",
      "yes\n",
      "322\n",
      "yes\n",
      "323\n",
      "yes\n",
      "324\n",
      "yes\n",
      "325\n",
      "yes\n",
      "326\n",
      "yes\n",
      "327\n",
      "yes\n",
      "328\n",
      "yes\n",
      "329\n",
      "yes\n",
      "330\n",
      "yes\n",
      "331\n",
      "yes\n",
      "332\n",
      "yes\n",
      "333\n",
      "yes\n",
      "334\n",
      "yes\n",
      "335\n",
      "yes\n",
      "336\n",
      "yes\n",
      "337\n",
      "yes\n",
      "338\n",
      "yes\n",
      "339\n",
      "yes\n",
      "340\n",
      "yes\n",
      "341\n",
      "yes\n",
      "342\n",
      "yes\n",
      "343\n",
      "yes\n",
      "344\n",
      "yes\n",
      "345\n",
      "yes\n",
      "346\n",
      "yes\n",
      "347\n",
      "yes\n",
      "348\n",
      "yes\n",
      "349\n",
      "yes\n",
      "350\n",
      "yes\n",
      "351\n",
      "yes\n",
      "352\n",
      "yes\n",
      "353\n",
      "yes\n",
      "354\n",
      "yes\n",
      "355\n",
      "yes\n",
      "356\n",
      "yes\n",
      "357\n",
      "yes\n",
      "358\n",
      "yes\n",
      "359\n",
      "yes\n",
      "360\n",
      "yes\n",
      "361\n",
      "yes\n",
      "362\n",
      "yes\n",
      "363\n",
      "yes\n",
      "364\n",
      "yes\n",
      "365\n",
      "yes\n",
      "366\n",
      "yes\n",
      "367\n",
      "yes\n",
      "368\n",
      "yes\n",
      "369\n",
      "yes\n",
      "370\n",
      "yes\n",
      "371\n",
      "yes\n",
      "372\n",
      "yes\n",
      "373\n",
      "yes\n",
      "374\n",
      "yes\n",
      "375\n",
      "yes\n",
      "376\n",
      "yes\n",
      "377\n",
      "yes\n",
      "378\n",
      "yes\n",
      "379\n",
      "yes\n",
      "380\n",
      "yes\n",
      "381\n",
      "yes\n",
      "382\n",
      "yes\n",
      "383\n",
      "yes\n",
      "384\n",
      "yes\n",
      "385\n",
      "yes\n",
      "386\n",
      "yes\n",
      "387\n",
      "yes\n",
      "388\n",
      "yes\n",
      "389\n",
      "yes\n",
      "390\n",
      "yes\n",
      "391\n",
      "yes\n",
      "392\n",
      "yes\n",
      "393\n",
      "yes\n",
      "394\n",
      "yes\n",
      "395\n",
      "yes\n",
      "396\n",
      "yes\n",
      "397\n",
      "yes\n",
      "398\n",
      "yes\n",
      "399\n",
      "yes\n",
      "400\n",
      "yes\n",
      "401\n",
      "yes\n",
      "402\n",
      "yes\n",
      "403\n",
      "yes\n",
      "404\n",
      "yes\n",
      "405\n",
      "yes\n",
      "406\n",
      "yes\n",
      "407\n",
      "yes\n",
      "408\n",
      "yes\n",
      "409\n",
      "yes\n",
      "410\n",
      "yes\n",
      "411\n",
      "yes\n",
      "412\n",
      "yes\n",
      "413\n",
      "yes\n",
      "414\n",
      "yes\n",
      "415\n",
      "yes\n",
      "416\n",
      "yes\n",
      "417\n",
      "yes\n",
      "418\n",
      "yes\n",
      "419\n",
      "yes\n",
      "420\n",
      "yes\n",
      "421\n",
      "yes\n",
      "422\n",
      "yes\n",
      "423\n",
      "yes\n",
      "424\n",
      "yes\n",
      "425\n",
      "yes\n",
      "426\n",
      "yes\n",
      "427\n",
      "yes\n",
      "428\n",
      "yes\n",
      "429\n",
      "yes\n",
      "430\n",
      "yes\n",
      "431\n",
      "yes\n",
      "432\n",
      "yes\n",
      "433\n",
      "yes\n",
      "434\n",
      "yes\n",
      "435\n",
      "yes\n",
      "436\n",
      "yes\n",
      "437\n",
      "yes\n",
      "438\n",
      "yes\n",
      "439\n",
      "yes\n",
      "440\n",
      "yes\n",
      "441\n",
      "yes\n",
      "442\n",
      "yes\n",
      "443\n",
      "yes\n",
      "444\n",
      "yes\n",
      "445\n",
      "yes\n",
      "446\n",
      "yes\n",
      "447\n",
      "yes\n",
      "448\n",
      "yes\n",
      "449\n",
      "yes\n",
      "450\n",
      "yes\n",
      "451\n",
      "yes\n",
      "452\n",
      "yes\n",
      "453\n",
      "yes\n",
      "454\n",
      "yes\n",
      "455\n",
      "yes\n",
      "456\n",
      "yes\n",
      "457\n",
      "yes\n",
      "458\n",
      "yes\n",
      "459\n",
      "yes\n",
      "460\n",
      "yes\n",
      "461\n",
      "yes\n",
      "462\n",
      "yes\n",
      "463\n",
      "yes\n",
      "464\n",
      "yes\n",
      "465\n",
      "yes\n",
      "466\n",
      "yes\n",
      "467\n",
      "yes\n",
      "468\n",
      "yes\n",
      "469\n",
      "yes\n",
      "470\n",
      "yes\n",
      "471\n",
      "yes\n",
      "472\n",
      "yes\n",
      "473\n",
      "yes\n",
      "474\n",
      "yes\n",
      "475\n",
      "yes\n",
      "476\n",
      "yes\n",
      "477\n",
      "yes\n",
      "478\n",
      "yes\n",
      "479\n",
      "yes\n",
      "480\n",
      "yes\n",
      "481\n",
      "yes\n",
      "482\n",
      "yes\n",
      "483\n",
      "yes\n",
      "484\n",
      "yes\n",
      "485\n",
      "yes\n",
      "486\n",
      "yes\n",
      "487\n",
      "yes\n",
      "488\n",
      "yes\n",
      "489\n",
      "yes\n",
      "490\n",
      "yes\n",
      "491\n",
      "yes\n",
      "492\n",
      "yes\n",
      "493\n",
      "yes\n",
      "494\n",
      "yes\n",
      "495\n",
      "yes\n",
      "496\n",
      "yes\n",
      "497\n",
      "yes\n",
      "498\n",
      "yes\n",
      "499\n",
      "yes\n",
      "500\n",
      "yes\n",
      "501\n",
      "yes\n",
      "502\n",
      "yes\n",
      "503\n",
      "yes\n",
      "504\n",
      "yes\n",
      "505\n",
      "yes\n",
      "506\n",
      "yes\n",
      "507\n",
      "yes\n",
      "508\n",
      "yes\n",
      "509\n",
      "yes\n",
      "510\n",
      "yes\n",
      "511\n",
      "yes\n",
      "512\n",
      "yes\n",
      "513\n",
      "yes\n",
      "514\n",
      "yes\n",
      "515\n",
      "yes\n",
      "516\n",
      "yes\n",
      "517\n",
      "yes\n",
      "518\n",
      "yes\n",
      "519\n",
      "yes\n",
      "520\n",
      "yes\n",
      "521\n",
      "yes\n",
      "522\n",
      "yes\n",
      "523\n",
      "yes\n",
      "524\n",
      "yes\n",
      "525\n",
      "yes\n",
      "526\n",
      "yes\n",
      "527\n",
      "yes\n",
      "528\n",
      "yes\n",
      "529\n",
      "yes\n",
      "530\n",
      "yes\n",
      "531\n",
      "yes\n",
      "532\n",
      "yes\n",
      "533\n",
      "yes\n",
      "534\n",
      "yes\n",
      "535\n",
      "yes\n",
      "536\n",
      "yes\n",
      "537\n",
      "yes\n",
      "538\n",
      "yes\n",
      "539\n",
      "yes\n",
      "540\n",
      "yes\n",
      "541\n",
      "yes\n",
      "542\n",
      "yes\n",
      "543\n",
      "yes\n",
      "544\n",
      "yes\n",
      "545\n",
      "yes\n",
      "546\n",
      "yes\n",
      "547\n",
      "yes\n",
      "548\n",
      "yes\n",
      "549\n",
      "yes\n",
      "550\n",
      "yes\n",
      "551\n",
      "yes\n",
      "552\n",
      "yes\n",
      "553\n",
      "yes\n",
      "554\n",
      "yes\n",
      "555\n",
      "yes\n",
      "556\n",
      "yes\n",
      "557\n",
      "yes\n",
      "558\n",
      "yes\n",
      "559\n",
      "yes\n",
      "560\n",
      "yes\n",
      "561\n",
      "yes\n",
      "562\n",
      "yes\n",
      "563\n",
      "yes\n",
      "564\n",
      "yes\n",
      "565\n",
      "yes\n",
      "566\n",
      "yes\n",
      "567\n",
      "yes\n",
      "568\n",
      "yes\n",
      "569\n",
      "yes\n",
      "570\n",
      "yes\n",
      "571\n",
      "yes\n",
      "572\n",
      "yes\n",
      "573\n",
      "yes\n",
      "574\n",
      "yes\n",
      "575\n",
      "yes\n",
      "576\n",
      "yes\n",
      "577\n",
      "yes\n",
      "578\n",
      "yes\n",
      "579\n",
      "yes\n",
      "580\n",
      "yes\n",
      "581\n",
      "yes\n",
      "582\n",
      "yes\n",
      "583\n",
      "yes\n",
      "584\n",
      "yes\n",
      "585\n",
      "yes\n",
      "586\n",
      "yes\n",
      "587\n",
      "yes\n",
      "588\n",
      "yes\n",
      "589\n",
      "yes\n",
      "590\n",
      "yes\n",
      "591\n",
      "yes\n",
      "592\n",
      "yes\n",
      "593\n",
      "yes\n",
      "594\n",
      "yes\n",
      "595\n",
      "yes\n",
      "596\n",
      "yes\n",
      "597\n",
      "yes\n",
      "598\n",
      "yes\n",
      "599\n",
      "yes\n",
      "600\n",
      "yes\n",
      "601\n",
      "yes\n",
      "602\n",
      "yes\n",
      "603\n",
      "yes\n",
      "604\n",
      "yes\n",
      "605\n",
      "yes\n",
      "606\n",
      "yes\n",
      "607\n",
      "yes\n",
      "608\n",
      "yes\n",
      "609\n",
      "yes\n",
      "610\n",
      "yes\n",
      "611\n",
      "yes\n",
      "612\n",
      "yes\n",
      "613\n",
      "yes\n",
      "614\n",
      "yes\n",
      "615\n",
      "yes\n",
      "616\n",
      "yes\n",
      "617\n",
      "yes\n",
      "618\n",
      "yes\n",
      "619\n",
      "yes\n",
      "620\n",
      "yes\n",
      "621\n",
      "yes\n",
      "622\n",
      "yes\n",
      "623\n",
      "yes\n",
      "624\n",
      "yes\n",
      "625\n",
      "yes\n",
      "626\n",
      "yes\n",
      "627\n",
      "yes\n",
      "628\n",
      "yes\n",
      "629\n",
      "yes\n",
      "630\n",
      "yes\n",
      "631\n",
      "yes\n",
      "632\n",
      "yes\n",
      "633\n",
      "yes\n",
      "634\n",
      "yes\n",
      "635\n",
      "yes\n",
      "636\n",
      "yes\n",
      "637\n",
      "yes\n",
      "638\n",
      "yes\n",
      "639\n",
      "yes\n",
      "640\n",
      "yes\n",
      "641\n",
      "yes\n",
      "642\n",
      "yes\n",
      "643\n",
      "yes\n",
      "644\n",
      "yes\n",
      "645\n",
      "yes\n",
      "646\n",
      "yes\n",
      "647\n",
      "yes\n",
      "648\n",
      "yes\n",
      "649\n",
      "yes\n",
      "650\n",
      "yes\n",
      "651\n",
      "yes\n",
      "652\n",
      "yes\n",
      "653\n",
      "yes\n",
      "654\n",
      "yes\n",
      "655\n",
      "yes\n",
      "656\n",
      "yes\n",
      "657\n",
      "yes\n",
      "658\n",
      "yes\n",
      "659\n",
      "yes\n",
      "660\n",
      "yes\n",
      "661\n",
      "yes\n",
      "662\n",
      "yes\n",
      "663\n",
      "yes\n",
      "664\n",
      "yes\n",
      "665\n",
      "yes\n",
      "666\n",
      "yes\n",
      "667\n",
      "yes\n",
      "668\n",
      "yes\n",
      "669\n",
      "yes\n",
      "670\n",
      "yes\n",
      "671\n",
      "yes\n",
      "672\n",
      "yes\n",
      "673\n",
      "yes\n",
      "674\n",
      "yes\n",
      "675\n",
      "yes\n",
      "676\n",
      "yes\n",
      "677\n",
      "yes\n",
      "678\n",
      "yes\n",
      "679\n",
      "yes\n",
      "680\n",
      "yes\n",
      "681\n",
      "yes\n",
      "682\n",
      "yes\n",
      "683\n",
      "yes\n",
      "684\n",
      "yes\n",
      "685\n",
      "yes\n",
      "686\n",
      "yes\n",
      "687\n",
      "yes\n",
      "688\n",
      "yes\n",
      "689\n",
      "yes\n",
      "690\n",
      "yes\n",
      "691\n",
      "yes\n",
      "692\n",
      "yes\n",
      "693\n",
      "yes\n",
      "694\n",
      "yes\n",
      "695\n",
      "yes\n",
      "696\n",
      "yes\n",
      "697\n",
      "yes\n",
      "698\n",
      "yes\n",
      "699\n",
      "yes\n",
      "700\n",
      "yes\n",
      "701\n",
      "yes\n",
      "702\n",
      "yes\n",
      "703\n",
      "yes\n",
      "704\n",
      "yes\n",
      "705\n",
      "yes\n",
      "706\n",
      "yes\n",
      "707\n",
      "yes\n",
      "708\n",
      "yes\n",
      "709\n",
      "yes\n",
      "710\n",
      "yes\n",
      "711\n",
      "yes\n",
      "712\n",
      "yes\n",
      "713\n",
      "yes\n",
      "714\n",
      "yes\n",
      "715\n",
      "yes\n",
      "716\n",
      "yes\n",
      "717\n",
      "yes\n",
      "718\n",
      "yes\n",
      "719\n",
      "yes\n",
      "720\n",
      "yes\n",
      "721\n",
      "yes\n",
      "722\n",
      "yes\n",
      "723\n",
      "yes\n",
      "724\n",
      "yes\n",
      "725\n",
      "yes\n",
      "726\n",
      "yes\n",
      "727\n",
      "yes\n",
      "728\n",
      "yes\n",
      "729\n",
      "yes\n",
      "730\n",
      "yes\n",
      "731\n",
      "yes\n",
      "732\n",
      "yes\n",
      "733\n",
      "yes\n",
      "734\n",
      "yes\n",
      "735\n",
      "yes\n",
      "736\n",
      "yes\n",
      "737\n",
      "yes\n",
      "738\n",
      "yes\n",
      "739\n",
      "yes\n",
      "740\n",
      "yes\n",
      "741\n",
      "yes\n",
      "742\n",
      "yes\n",
      "743\n",
      "yes\n",
      "744\n",
      "yes\n",
      "745\n",
      "yes\n",
      "746\n",
      "yes\n",
      "747\n",
      "yes\n",
      "748\n",
      "yes\n",
      "749\n",
      "yes\n",
      "750\n",
      "yes\n",
      "751\n",
      "yes\n",
      "752\n",
      "yes\n",
      "753\n",
      "yes\n",
      "754\n",
      "yes\n",
      "755\n",
      "yes\n",
      "756\n",
      "yes\n",
      "757\n",
      "yes\n",
      "758\n",
      "yes\n",
      "759\n",
      "yes\n",
      "760\n",
      "yes\n",
      "761\n",
      "yes\n",
      "762\n",
      "yes\n",
      "763\n",
      "yes\n",
      "764\n",
      "yes\n",
      "765\n",
      "yes\n",
      "766\n",
      "yes\n",
      "767\n",
      "yes\n",
      "768\n",
      "yes\n",
      "769\n",
      "yes\n",
      "770\n",
      "yes\n",
      "771\n",
      "yes\n",
      "772\n",
      "yes\n",
      "773\n",
      "yes\n",
      "774\n",
      "yes\n",
      "775\n",
      "yes\n",
      "776\n",
      "yes\n",
      "777\n",
      "yes\n",
      "778\n",
      "yes\n",
      "779\n",
      "yes\n",
      "780\n",
      "yes\n",
      "781\n",
      "yes\n",
      "782\n",
      "yes\n",
      "783\n",
      "yes\n",
      "784\n",
      "yes\n",
      "785\n",
      "yes\n",
      "786\n",
      "yes\n",
      "787\n",
      "yes\n",
      "788\n",
      "yes\n",
      "789\n",
      "yes\n",
      "790\n",
      "yes\n",
      "791\n",
      "yes\n",
      "792\n",
      "yes\n",
      "793\n",
      "yes\n",
      "794\n",
      "yes\n",
      "795\n",
      "yes\n",
      "796\n",
      "yes\n",
      "797\n",
      "yes\n",
      "798\n",
      "yes\n",
      "799\n",
      "yes\n",
      "800\n",
      "yes\n",
      "801\n",
      "yes\n",
      "802\n",
      "yes\n",
      "803\n",
      "yes\n",
      "804\n",
      "yes\n",
      "805\n",
      "yes\n",
      "806\n",
      "yes\n",
      "807\n",
      "yes\n",
      "808\n",
      "yes\n",
      "809\n",
      "yes\n",
      "810\n",
      "yes\n",
      "811\n",
      "yes\n",
      "812\n",
      "yes\n",
      "813\n",
      "yes\n",
      "814\n",
      "yes\n",
      "815\n",
      "yes\n",
      "816\n",
      "yes\n",
      "817\n",
      "yes\n",
      "818\n",
      "yes\n",
      "819\n",
      "yes\n",
      "820\n",
      "yes\n",
      "821\n",
      "yes\n",
      "822\n",
      "yes\n",
      "823\n",
      "yes\n",
      "824\n",
      "yes\n",
      "825\n",
      "yes\n",
      "826\n",
      "yes\n",
      "827\n",
      "yes\n",
      "828\n",
      "yes\n",
      "829\n",
      "yes\n",
      "830\n",
      "yes\n",
      "831\n",
      "yes\n",
      "832\n",
      "yes\n",
      "833\n",
      "yes\n",
      "834\n",
      "yes\n",
      "835\n",
      "yes\n",
      "836\n",
      "yes\n",
      "837\n",
      "yes\n",
      "838\n",
      "yes\n",
      "839\n",
      "yes\n",
      "840\n",
      "yes\n",
      "841\n",
      "yes\n",
      "842\n",
      "yes\n",
      "843\n",
      "yes\n",
      "844\n",
      "yes\n",
      "845\n",
      "yes\n",
      "846\n",
      "yes\n",
      "847\n",
      "yes\n",
      "848\n",
      "yes\n",
      "849\n",
      "yes\n",
      "850\n",
      "yes\n",
      "851\n",
      "yes\n",
      "852\n",
      "yes\n",
      "853\n",
      "yes\n",
      "854\n",
      "yes\n",
      "855\n",
      "yes\n",
      "856\n",
      "yes\n",
      "857\n",
      "yes\n",
      "858\n",
      "yes\n",
      "859\n",
      "yes\n",
      "860\n",
      "yes\n",
      "861\n",
      "yes\n",
      "862\n",
      "yes\n",
      "863\n",
      "yes\n",
      "864\n",
      "yes\n",
      "865\n",
      "yes\n",
      "866\n",
      "yes\n",
      "867\n",
      "yes\n",
      "868\n",
      "yes\n",
      "869\n",
      "yes\n",
      "870\n",
      "yes\n",
      "871\n",
      "yes\n",
      "872\n",
      "yes\n",
      "873\n",
      "yes\n",
      "874\n",
      "yes\n",
      "875\n",
      "yes\n",
      "876\n",
      "yes\n",
      "877\n",
      "yes\n",
      "878\n",
      "yes\n",
      "879\n",
      "yes\n",
      "880\n",
      "yes\n",
      "881\n",
      "yes\n",
      "882\n",
      "yes\n",
      "883\n",
      "yes\n",
      "884\n",
      "yes\n",
      "885\n",
      "yes\n",
      "886\n",
      "yes\n",
      "887\n",
      "yes\n",
      "888\n",
      "yes\n",
      "889\n",
      "yes\n",
      "890\n",
      "yes\n",
      "891\n",
      "yes\n",
      "892\n",
      "yes\n",
      "893\n",
      "yes\n",
      "894\n",
      "yes\n",
      "895\n",
      "yes\n",
      "896\n",
      "yes\n",
      "897\n",
      "yes\n",
      "898\n",
      "yes\n",
      "899\n",
      "yes\n",
      "900\n",
      "yes\n",
      "901\n",
      "yes\n",
      "902\n",
      "yes\n",
      "903\n",
      "yes\n",
      "904\n",
      "yes\n",
      "905\n",
      "yes\n",
      "906\n",
      "yes\n",
      "907\n",
      "yes\n",
      "908\n",
      "yes\n",
      "909\n",
      "yes\n",
      "910\n",
      "yes\n",
      "911\n",
      "yes\n",
      "912\n",
      "yes\n",
      "913\n",
      "yes\n",
      "914\n",
      "yes\n",
      "915\n",
      "yes\n",
      "916\n",
      "yes\n",
      "917\n",
      "yes\n",
      "918\n",
      "yes\n",
      "919\n",
      "yes\n",
      "920\n",
      "yes\n",
      "921\n",
      "yes\n",
      "922\n",
      "yes\n",
      "923\n",
      "yes\n",
      "924\n",
      "yes\n",
      "925\n",
      "yes\n",
      "926\n",
      "yes\n",
      "927\n",
      "yes\n",
      "928\n",
      "yes\n",
      "929\n",
      "yes\n",
      "930\n",
      "yes\n",
      "931\n",
      "yes\n",
      "932\n",
      "yes\n",
      "933\n",
      "yes\n",
      "934\n",
      "yes\n",
      "935\n",
      "yes\n",
      "936\n",
      "yes\n",
      "937\n",
      "yes\n",
      "938\n",
      "yes\n",
      "939\n",
      "yes\n",
      "940\n",
      "yes\n",
      "941\n",
      "yes\n",
      "942\n",
      "yes\n",
      "943\n",
      "yes\n",
      "944\n",
      "yes\n",
      "945\n",
      "yes\n",
      "946\n",
      "yes\n",
      "947\n",
      "yes\n",
      "948\n",
      "yes\n",
      "949\n",
      "yes\n",
      "950\n",
      "yes\n",
      "951\n",
      "yes\n",
      "952\n",
      "yes\n",
      "953\n",
      "yes\n",
      "954\n",
      "yes\n",
      "955\n",
      "yes\n",
      "956\n",
      "yes\n",
      "957\n",
      "yes\n",
      "958\n",
      "yes\n",
      "959\n",
      "yes\n",
      "960\n",
      "yes\n",
      "961\n",
      "yes\n",
      "962\n",
      "yes\n",
      "963\n",
      "yes\n",
      "964\n",
      "yes\n",
      "965\n",
      "yes\n",
      "966\n",
      "yes\n",
      "967\n",
      "yes\n",
      "968\n",
      "yes\n",
      "969\n",
      "yes\n",
      "970\n",
      "yes\n",
      "971\n",
      "yes\n",
      "972\n",
      "yes\n",
      "973\n",
      "yes\n",
      "974\n",
      "yes\n",
      "975\n",
      "yes\n",
      "976\n",
      "yes\n",
      "977\n",
      "yes\n",
      "978\n",
      "yes\n",
      "979\n",
      "yes\n",
      "980\n",
      "yes\n",
      "981\n",
      "yes\n",
      "982\n",
      "yes\n",
      "983\n",
      "yes\n",
      "984\n",
      "yes\n",
      "985\n",
      "yes\n",
      "986\n",
      "yes\n",
      "987\n",
      "yes\n",
      "988\n",
      "yes\n",
      "989\n",
      "yes\n",
      "990\n",
      "yes\n",
      "991\n",
      "yes\n",
      "992\n",
      "yes\n",
      "993\n",
      "yes\n",
      "994\n",
      "yes\n",
      "995\n",
      "yes\n",
      "996\n",
      "yes\n",
      "997\n",
      "yes\n",
      "998\n",
      "yes\n",
      "999\n",
      "yes\n",
      "1000\n",
      "yes\n",
      "1001\n",
      "yes\n",
      "1002\n",
      "yes\n",
      "1003\n",
      "yes\n",
      "1004\n",
      "yes\n",
      "1005\n",
      "yes\n",
      "1006\n",
      "yes\n",
      "1007\n",
      "yes\n",
      "1008\n",
      "yes\n",
      "1009\n",
      "yes\n",
      "1010\n",
      "yes\n",
      "1011\n",
      "yes\n",
      "1012\n",
      "yes\n",
      "1013\n",
      "yes\n",
      "1014\n",
      "yes\n",
      "1015\n",
      "yes\n",
      "1016\n",
      "yes\n",
      "1017\n",
      "yes\n",
      "1018\n",
      "yes\n",
      "1019\n",
      "yes\n",
      "1020\n",
      "yes\n",
      "1021\n",
      "yes\n",
      "1022\n",
      "yes\n",
      "1023\n",
      "yes\n",
      "1024\n",
      "yes\n",
      "1025\n",
      "yes\n",
      "1026\n",
      "yes\n",
      "1027\n",
      "yes\n",
      "1028\n",
      "yes\n",
      "1029\n",
      "yes\n",
      "1030\n",
      "yes\n",
      "1031\n",
      "yes\n",
      "1032\n",
      "yes\n",
      "1033\n",
      "yes\n",
      "1034\n",
      "yes\n",
      "1035\n",
      "yes\n",
      "1036\n",
      "yes\n",
      "1037\n",
      "yes\n",
      "1038\n",
      "yes\n",
      "1039\n",
      "yes\n",
      "1040\n",
      "yes\n",
      "1041\n",
      "yes\n",
      "1042\n",
      "yes\n",
      "1043\n",
      "yes\n",
      "1044\n",
      "yes\n",
      "1045\n",
      "yes\n",
      "1046\n",
      "yes\n",
      "1047\n",
      "yes\n",
      "1048\n",
      "yes\n",
      "1049\n",
      "yes\n",
      "1050\n",
      "yes\n",
      "1051\n",
      "yes\n",
      "1052\n",
      "yes\n",
      "1053\n",
      "yes\n",
      "1054\n",
      "yes\n",
      "1055\n",
      "yes\n",
      "1056\n",
      "yes\n",
      "1057\n",
      "yes\n",
      "1058\n",
      "yes\n",
      "1059\n",
      "yes\n",
      "1060\n",
      "yes\n",
      "1061\n",
      "yes\n",
      "1062\n",
      "yes\n",
      "1063\n",
      "yes\n",
      "1064\n",
      "yes\n",
      "1065\n",
      "yes\n",
      "1066\n",
      "yes\n",
      "1067\n",
      "yes\n",
      "1068\n",
      "yes\n",
      "1069\n",
      "yes\n",
      "1070\n",
      "yes\n",
      "1071\n",
      "yes\n",
      "1072\n",
      "yes\n",
      "1073\n",
      "yes\n",
      "1074\n",
      "yes\n",
      "1075\n",
      "yes\n",
      "1076\n",
      "yes\n",
      "1077\n",
      "yes\n",
      "1078\n",
      "yes\n",
      "1079\n",
      "yes\n",
      "1080\n",
      "yes\n",
      "1081\n",
      "yes\n",
      "1082\n",
      "yes\n",
      "1083\n",
      "yes\n",
      "1084\n",
      "yes\n",
      "1085\n",
      "yes\n",
      "1086\n",
      "yes\n",
      "1087\n",
      "yes\n",
      "1088\n",
      "yes\n",
      "1089\n",
      "yes\n",
      "1090\n",
      "yes\n",
      "1091\n",
      "yes\n",
      "1092\n",
      "yes\n",
      "1093\n",
      "yes\n",
      "1094\n",
      "yes\n",
      "1095\n",
      "yes\n",
      "1096\n",
      "yes\n",
      "1097\n",
      "yes\n",
      "1098\n",
      "yes\n",
      "1099\n",
      "yes\n",
      "1100\n",
      "yes\n",
      "1101\n",
      "yes\n",
      "1102\n",
      "yes\n",
      "1103\n",
      "yes\n",
      "1104\n",
      "yes\n",
      "1105\n",
      "yes\n",
      "1106\n",
      "yes\n",
      "1107\n",
      "yes\n",
      "1108\n",
      "yes\n",
      "1109\n",
      "yes\n",
      "1110\n",
      "yes\n",
      "1111\n",
      "yes\n",
      "1112\n",
      "yes\n",
      "1113\n",
      "yes\n",
      "1114\n",
      "yes\n",
      "1115\n",
      "yes\n",
      "1116\n",
      "yes\n",
      "1117\n",
      "yes\n",
      "1118\n",
      "yes\n",
      "1119\n",
      "yes\n",
      "1120\n",
      "yes\n",
      "1121\n",
      "yes\n",
      "1122\n",
      "yes\n",
      "1123\n",
      "yes\n",
      "1124\n",
      "yes\n",
      "1125\n",
      "yes\n",
      "1126\n",
      "yes\n",
      "1127\n",
      "yes\n",
      "1128\n",
      "yes\n",
      "1129\n",
      "yes\n",
      "1130\n",
      "yes\n",
      "1131\n",
      "yes\n",
      "1132\n",
      "yes\n",
      "1133\n",
      "yes\n",
      "1134\n",
      "yes\n",
      "1135\n",
      "yes\n",
      "1136\n",
      "yes\n",
      "1137\n",
      "yes\n",
      "1138\n",
      "yes\n",
      "1139\n",
      "yes\n",
      "1140\n",
      "yes\n",
      "1141\n",
      "yes\n",
      "1142\n",
      "yes\n",
      "1143\n",
      "yes\n",
      "1144\n",
      "yes\n",
      "1145\n",
      "yes\n",
      "1146\n",
      "yes\n",
      "1147\n",
      "yes\n",
      "1148\n",
      "yes\n",
      "1149\n",
      "yes\n",
      "1150\n",
      "yes\n",
      "1151\n",
      "yes\n",
      "1152\n",
      "yes\n",
      "1153\n",
      "yes\n",
      "1154\n",
      "yes\n",
      "1155\n",
      "yes\n",
      "1156\n",
      "yes\n",
      "1157\n",
      "yes\n",
      "1158\n",
      "yes\n",
      "1159\n",
      "yes\n",
      "1160\n",
      "yes\n",
      "1161\n",
      "yes\n",
      "1162\n",
      "yes\n",
      "1163\n",
      "yes\n",
      "1164\n",
      "yes\n",
      "1165\n",
      "yes\n",
      "1166\n",
      "yes\n",
      "1167\n",
      "yes\n",
      "1168\n",
      "yes\n",
      "1169\n",
      "yes\n",
      "1170\n",
      "yes\n",
      "1171\n",
      "yes\n",
      "1172\n",
      "yes\n",
      "1173\n",
      "yes\n",
      "1174\n",
      "yes\n",
      "1175\n",
      "yes\n",
      "1176\n",
      "yes\n",
      "1177\n",
      "yes\n",
      "1178\n",
      "yes\n",
      "1179\n",
      "yes\n",
      "1180\n",
      "yes\n",
      "1181\n",
      "yes\n",
      "1182\n",
      "yes\n",
      "1183\n",
      "yes\n",
      "1184\n",
      "yes\n",
      "1185\n",
      "yes\n",
      "1186\n",
      "yes\n",
      "1187\n",
      "yes\n",
      "1188\n",
      "yes\n",
      "1189\n",
      "yes\n",
      "1190\n",
      "yes\n",
      "1191\n",
      "yes\n",
      "1192\n",
      "yes\n",
      "1193\n",
      "yes\n",
      "1194\n",
      "yes\n",
      "1195\n",
      "yes\n",
      "1196\n",
      "yes\n",
      "1197\n",
      "yes\n",
      "1198\n",
      "yes\n",
      "1199\n",
      "yes\n",
      "1200\n",
      "yes\n",
      "1201\n",
      "yes\n",
      "1202\n",
      "yes\n",
      "1203\n",
      "yes\n",
      "1204\n",
      "yes\n",
      "1205\n",
      "yes\n",
      "1206\n",
      "yes\n",
      "1207\n",
      "yes\n",
      "1208\n",
      "yes\n",
      "1209\n",
      "yes\n",
      "1210\n",
      "yes\n",
      "1211\n",
      "yes\n",
      "1212\n",
      "yes\n",
      "1213\n",
      "yes\n",
      "1214\n",
      "yes\n",
      "1215\n",
      "yes\n",
      "1216\n",
      "yes\n",
      "1217\n",
      "yes\n",
      "1218\n",
      "yes\n",
      "1219\n",
      "yes\n",
      "1220\n",
      "yes\n",
      "1221\n",
      "yes\n",
      "1222\n",
      "yes\n",
      "1223\n",
      "yes\n",
      "1224\n",
      "yes\n",
      "1225\n",
      "yes\n",
      "1226\n",
      "yes\n",
      "1227\n",
      "yes\n",
      "1228\n",
      "yes\n",
      "1229\n",
      "yes\n",
      "1230\n",
      "yes\n",
      "1231\n",
      "yes\n",
      "1232\n",
      "yes\n",
      "1233\n",
      "yes\n",
      "1234\n",
      "yes\n",
      "1235\n",
      "yes\n",
      "1236\n",
      "yes\n",
      "1237\n",
      "yes\n",
      "1238\n",
      "yes\n",
      "1239\n",
      "yes\n",
      "1240\n",
      "yes\n",
      "1241\n",
      "yes\n",
      "1242\n",
      "yes\n",
      "1243\n",
      "yes\n",
      "1244\n",
      "yes\n",
      "1245\n",
      "yes\n",
      "1246\n",
      "yes\n",
      "1247\n",
      "yes\n",
      "1248\n",
      "yes\n",
      "1249\n",
      "yes\n",
      "1250\n",
      "yes\n",
      "1251\n",
      "yes\n",
      "1252\n",
      "yes\n",
      "1253\n",
      "yes\n",
      "1254\n",
      "yes\n",
      "1255\n",
      "yes\n",
      "1256\n",
      "yes\n",
      "1257\n",
      "yes\n",
      "1258\n",
      "yes\n",
      "1259\n",
      "yes\n",
      "1260\n",
      "yes\n",
      "1261\n",
      "yes\n",
      "1262\n",
      "yes\n",
      "1263\n",
      "yes\n",
      "1264\n",
      "yes\n",
      "1265\n",
      "yes\n",
      "1266\n",
      "yes\n",
      "1267\n",
      "yes\n",
      "1268\n",
      "yes\n",
      "1269\n",
      "yes\n",
      "1270\n",
      "yes\n",
      "1271\n",
      "yes\n",
      "1272\n",
      "yes\n",
      "1273\n",
      "yes\n",
      "1274\n",
      "yes\n",
      "1275\n",
      "yes\n",
      "1276\n",
      "yes\n",
      "1277\n",
      "yes\n",
      "1278\n",
      "yes\n",
      "1279\n",
      "yes\n",
      "1280\n",
      "yes\n",
      "1281\n",
      "yes\n",
      "1282\n",
      "yes\n",
      "1283\n",
      "yes\n",
      "1284\n",
      "yes\n",
      "1285\n",
      "yes\n",
      "1286\n",
      "yes\n",
      "1287\n",
      "yes\n",
      "1288\n",
      "yes\n",
      "1289\n",
      "yes\n",
      "1290\n",
      "yes\n",
      "1291\n",
      "yes\n",
      "1292\n",
      "yes\n",
      "1293\n",
      "yes\n",
      "1294\n",
      "yes\n",
      "1295\n",
      "yes\n",
      "1296\n",
      "yes\n",
      "1297\n",
      "yes\n",
      "1298\n",
      "yes\n",
      "1299\n",
      "yes\n",
      "1300\n",
      "yes\n",
      "1301\n",
      "yes\n",
      "1302\n",
      "yes\n",
      "1303\n",
      "yes\n",
      "1304\n",
      "yes\n",
      "1305\n",
      "yes\n",
      "1306\n",
      "yes\n",
      "1307\n",
      "yes\n",
      "1308\n",
      "yes\n",
      "1309\n",
      "yes\n",
      "1310\n",
      "yes\n",
      "1311\n",
      "yes\n",
      "1312\n",
      "yes\n",
      "1313\n",
      "yes\n",
      "1314\n",
      "yes\n",
      "1315\n",
      "yes\n",
      "1316\n",
      "yes\n",
      "1317\n",
      "yes\n",
      "1318\n",
      "yes\n",
      "1319\n",
      "yes\n",
      "1320\n",
      "yes\n",
      "1321\n",
      "yes\n",
      "1322\n",
      "yes\n",
      "1323\n",
      "yes\n",
      "1324\n",
      "yes\n",
      "1325\n",
      "yes\n",
      "1326\n",
      "yes\n",
      "1327\n",
      "yes\n",
      "1328\n",
      "yes\n",
      "1329\n",
      "yes\n",
      "1330\n",
      "yes\n",
      "1331\n",
      "yes\n",
      "1332\n",
      "yes\n",
      "1333\n",
      "yes\n",
      "1334\n",
      "yes\n",
      "1335\n",
      "yes\n",
      "1336\n",
      "yes\n",
      "1337\n",
      "yes\n",
      "1338\n",
      "yes\n",
      "1339\n",
      "yes\n",
      "1340\n",
      "yes\n",
      "1341\n",
      "yes\n",
      "1342\n",
      "yes\n",
      "1343\n",
      "yes\n",
      "1344\n",
      "yes\n",
      "1345\n",
      "yes\n",
      "1346\n",
      "yes\n",
      "1347\n",
      "yes\n",
      "1348\n",
      "yes\n",
      "1349\n",
      "yes\n",
      "1350\n",
      "yes\n",
      "1351\n",
      "yes\n",
      "1352\n",
      "yes\n",
      "1353\n",
      "yes\n",
      "1354\n",
      "yes\n",
      "1355\n",
      "yes\n",
      "1356\n",
      "yes\n",
      "1357\n",
      "yes\n",
      "1358\n",
      "yes\n",
      "1359\n",
      "yes\n",
      "1360\n",
      "yes\n",
      "1361\n",
      "yes\n",
      "1362\n",
      "yes\n",
      "1363\n",
      "yes\n",
      "1364\n",
      "yes\n",
      "1365\n",
      "yes\n",
      "1366\n",
      "yes\n",
      "1367\n",
      "yes\n",
      "1368\n",
      "yes\n",
      "1369\n",
      "yes\n",
      "1370\n",
      "yes\n",
      "1371\n",
      "yes\n",
      "1372\n",
      "yes\n",
      "1373\n",
      "yes\n",
      "1374\n",
      "yes\n",
      "1375\n",
      "yes\n",
      "1376\n",
      "yes\n",
      "1377\n",
      "yes\n",
      "1378\n",
      "yes\n",
      "1379\n",
      "yes\n",
      "1380\n",
      "yes\n",
      "1381\n",
      "yes\n",
      "1382\n",
      "yes\n",
      "1383\n",
      "yes\n",
      "1384\n",
      "yes\n",
      "1385\n",
      "yes\n",
      "1386\n",
      "yes\n",
      "1387\n",
      "yes\n",
      "1388\n",
      "yes\n",
      "1389\n",
      "yes\n",
      "1390\n",
      "yes\n",
      "1391\n",
      "yes\n",
      "1392\n",
      "yes\n",
      "1393\n",
      "yes\n",
      "1394\n",
      "yes\n",
      "1395\n",
      "yes\n",
      "1396\n",
      "yes\n",
      "1397\n",
      "yes\n",
      "1398\n",
      "yes\n",
      "1399\n",
      "yes\n",
      "1400\n",
      "yes\n",
      "1401\n",
      "yes\n",
      "1402\n",
      "yes\n",
      "1403\n",
      "yes\n",
      "1404\n",
      "yes\n",
      "1405\n",
      "yes\n",
      "1406\n",
      "yes\n",
      "1407\n",
      "yes\n",
      "1408\n",
      "yes\n",
      "1409\n",
      "yes\n",
      "1410\n",
      "yes\n",
      "1411\n",
      "yes\n",
      "1412\n",
      "yes\n",
      "1413\n",
      "yes\n",
      "1414\n",
      "yes\n",
      "1415\n",
      "yes\n",
      "1416\n",
      "yes\n",
      "1417\n",
      "yes\n",
      "1418\n",
      "yes\n",
      "1419\n",
      "yes\n",
      "1420\n",
      "yes\n",
      "1421\n",
      "yes\n",
      "1422\n",
      "yes\n",
      "1423\n",
      "yes\n",
      "1424\n",
      "yes\n",
      "1425\n",
      "yes\n",
      "1426\n",
      "yes\n",
      "1427\n",
      "yes\n",
      "1428\n",
      "yes\n",
      "1429\n",
      "yes\n",
      "1430\n",
      "yes\n",
      "1431\n",
      "yes\n",
      "1432\n",
      "yes\n",
      "1433\n",
      "yes\n",
      "1434\n",
      "yes\n",
      "1435\n",
      "yes\n",
      "1436\n",
      "yes\n",
      "1437\n",
      "yes\n",
      "1438\n",
      "yes\n",
      "1439\n",
      "yes\n",
      "1440\n",
      "yes\n",
      "1441\n",
      "yes\n",
      "1442\n",
      "yes\n",
      "1443\n",
      "yes\n",
      "1444\n",
      "yes\n",
      "1445\n",
      "yes\n",
      "1446\n",
      "yes\n",
      "1447\n",
      "yes\n",
      "1448\n",
      "yes\n",
      "1449\n",
      "yes\n",
      "1450\n",
      "yes\n",
      "1451\n",
      "yes\n",
      "1452\n",
      "yes\n",
      "1453\n",
      "yes\n",
      "1454\n",
      "yes\n",
      "1455\n",
      "yes\n",
      "1456\n",
      "yes\n",
      "1457\n",
      "yes\n",
      "1458\n",
      "yes\n",
      "1459\n",
      "yes\n",
      "1460\n",
      "yes\n",
      "1461\n",
      "yes\n",
      "1462\n",
      "yes\n",
      "1463\n",
      "yes\n",
      "1464\n",
      "yes\n",
      "1465\n",
      "yes\n",
      "1466\n",
      "yes\n",
      "1467\n",
      "yes\n",
      "1468\n",
      "yes\n",
      "1469\n",
      "yes\n",
      "1470\n",
      "yes\n",
      "1471\n",
      "yes\n",
      "1472\n",
      "yes\n",
      "1473\n",
      "yes\n",
      "1474\n",
      "yes\n",
      "1475\n",
      "yes\n",
      "1476\n",
      "yes\n",
      "1477\n",
      "yes\n",
      "1478\n",
      "yes\n",
      "1479\n",
      "yes\n",
      "1480\n",
      "yes\n",
      "1481\n",
      "yes\n",
      "1482\n",
      "yes\n",
      "1483\n",
      "yes\n",
      "1484\n",
      "yes\n",
      "1485\n",
      "yes\n",
      "1486\n",
      "yes\n",
      "1487\n",
      "yes\n",
      "1488\n",
      "yes\n",
      "1489\n",
      "yes\n",
      "1490\n",
      "yes\n",
      "1491\n",
      "yes\n",
      "1492\n",
      "yes\n",
      "1493\n",
      "yes\n",
      "1494\n",
      "yes\n",
      "1495\n",
      "yes\n",
      "1496\n",
      "yes\n",
      "1497\n",
      "yes\n",
      "1498\n",
      "yes\n",
      "1499\n",
      "yes\n",
      "1500\n",
      "yes\n",
      "1501\n",
      "yes\n",
      "1502\n",
      "yes\n",
      "1503\n",
      "yes\n",
      "1504\n",
      "yes\n",
      "1505\n",
      "yes\n",
      "1506\n",
      "yes\n",
      "1507\n",
      "yes\n",
      "1508\n",
      "yes\n",
      "1509\n",
      "yes\n",
      "1510\n",
      "yes\n",
      "1511\n",
      "yes\n",
      "1512\n",
      "yes\n",
      "1513\n",
      "yes\n",
      "1514\n",
      "yes\n",
      "1515\n",
      "yes\n",
      "1516\n",
      "yes\n",
      "1517\n",
      "yes\n",
      "1518\n",
      "yes\n",
      "1519\n",
      "yes\n",
      "1520\n",
      "yes\n",
      "1521\n",
      "yes\n",
      "1522\n",
      "yes\n",
      "1523\n",
      "yes\n",
      "1524\n",
      "yes\n",
      "1525\n",
      "yes\n",
      "1526\n",
      "yes\n",
      "1527\n",
      "yes\n",
      "1528\n",
      "yes\n",
      "1529\n",
      "yes\n",
      "1530\n",
      "yes\n",
      "1531\n",
      "yes\n",
      "1532\n",
      "yes\n",
      "1533\n",
      "yes\n",
      "1534\n",
      "yes\n",
      "1535\n",
      "yes\n",
      "1536\n",
      "yes\n",
      "1537\n",
      "yes\n",
      "1538\n",
      "yes\n",
      "1539\n",
      "yes\n",
      "1540\n",
      "yes\n",
      "1541\n",
      "yes\n",
      "1542\n",
      "yes\n",
      "1543\n",
      "yes\n",
      "1544\n",
      "yes\n",
      "1545\n",
      "yes\n",
      "1546\n",
      "yes\n",
      "1547\n",
      "yes\n",
      "1548\n",
      "yes\n",
      "1549\n",
      "yes\n",
      "1550\n",
      "yes\n",
      "1551\n",
      "yes\n",
      "1552\n",
      "yes\n",
      "1553\n",
      "yes\n",
      "1554\n",
      "yes\n",
      "1555\n",
      "yes\n",
      "1556\n",
      "yes\n",
      "1557\n",
      "yes\n",
      "1558\n",
      "yes\n",
      "1559\n",
      "yes\n",
      "1560\n",
      "yes\n",
      "1561\n",
      "yes\n",
      "1562\n",
      "yes\n",
      "1563\n",
      "yes\n",
      "1564\n",
      "yes\n",
      "1565\n",
      "yes\n",
      "1566\n",
      "yes\n",
      "1567\n",
      "yes\n",
      "1568\n",
      "yes\n",
      "1569\n",
      "yes\n",
      "1570\n",
      "yes\n",
      "1571\n",
      "yes\n",
      "1572\n",
      "yes\n",
      "1573\n",
      "yes\n",
      "1574\n",
      "yes\n",
      "1575\n",
      "yes\n",
      "1576\n",
      "yes\n",
      "1577\n",
      "yes\n",
      "1578\n",
      "yes\n",
      "1579\n",
      "yes\n",
      "1580\n",
      "yes\n",
      "1581\n",
      "yes\n",
      "1582\n",
      "yes\n",
      "1583\n",
      "yes\n",
      "1584\n",
      "yes\n",
      "1585\n",
      "yes\n",
      "1586\n",
      "yes\n",
      "1587\n",
      "yes\n",
      "1588\n",
      "yes\n",
      "1589\n",
      "yes\n",
      "1590\n",
      "yes\n",
      "1591\n",
      "yes\n",
      "1592\n",
      "yes\n",
      "1593\n",
      "yes\n",
      "1594\n",
      "yes\n",
      "1595\n",
      "yes\n",
      "1596\n",
      "yes\n",
      "1597\n",
      "yes\n",
      "1598\n",
      "yes\n",
      "1599\n",
      "yes\n",
      "1600\n",
      "yes\n",
      "1601\n",
      "yes\n",
      "1602\n",
      "yes\n",
      "1603\n",
      "yes\n",
      "1604\n",
      "yes\n",
      "1605\n",
      "yes\n",
      "1606\n",
      "yes\n",
      "1607\n",
      "yes\n",
      "1608\n",
      "yes\n",
      "1609\n",
      "yes\n",
      "1610\n",
      "yes\n",
      "1611\n",
      "yes\n",
      "1612\n",
      "yes\n",
      "1613\n",
      "yes\n",
      "1614\n",
      "yes\n",
      "1615\n",
      "yes\n",
      "1616\n",
      "yes\n",
      "1617\n",
      "yes\n",
      "1618\n",
      "yes\n",
      "1619\n",
      "yes\n",
      "1620\n",
      "yes\n",
      "1621\n",
      "yes\n",
      "1622\n",
      "yes\n",
      "1623\n",
      "yes\n",
      "1624\n",
      "yes\n",
      "1625\n",
      "yes\n",
      "1626\n",
      "yes\n",
      "1627\n",
      "yes\n",
      "1628\n",
      "yes\n",
      "1629\n",
      "yes\n",
      "1630\n",
      "yes\n",
      "1631\n",
      "yes\n",
      "1632\n",
      "yes\n",
      "1633\n",
      "yes\n",
      "1634\n",
      "yes\n",
      "1635\n",
      "yes\n",
      "1636\n",
      "yes\n",
      "1637\n",
      "yes\n",
      "1638\n",
      "yes\n",
      "1639\n",
      "yes\n",
      "1640\n",
      "yes\n",
      "1641\n",
      "yes\n",
      "1642\n",
      "yes\n",
      "1643\n",
      "yes\n",
      "1644\n",
      "yes\n",
      "1645\n",
      "yes\n",
      "1646\n",
      "yes\n",
      "1647\n",
      "yes\n",
      "1648\n",
      "yes\n",
      "1649\n",
      "yes\n",
      "1650\n",
      "yes\n",
      "1651\n",
      "yes\n",
      "1652\n",
      "yes\n",
      "1653\n",
      "yes\n",
      "1654\n",
      "yes\n",
      "1655\n",
      "yes\n",
      "1656\n",
      "yes\n",
      "1657\n",
      "yes\n",
      "1658\n",
      "yes\n",
      "1659\n",
      "yes\n",
      "1660\n",
      "yes\n",
      "1661\n",
      "yes\n",
      "1662\n",
      "yes\n",
      "1663\n",
      "yes\n",
      "1664\n",
      "yes\n",
      "1665\n",
      "yes\n",
      "1666\n",
      "yes\n",
      "1667\n",
      "yes\n",
      "1668\n",
      "yes\n",
      "1669\n",
      "yes\n",
      "1670\n",
      "yes\n",
      "1671\n",
      "yes\n",
      "1672\n",
      "yes\n",
      "1673\n",
      "yes\n",
      "1674\n",
      "yes\n",
      "1675\n",
      "yes\n",
      "1676\n",
      "yes\n",
      "1677\n",
      "yes\n",
      "1678\n",
      "yes\n",
      "1679\n",
      "yes\n",
      "1680\n",
      "yes\n",
      "1681\n",
      "yes\n",
      "1682\n",
      "yes\n",
      "1683\n",
      "yes\n",
      "1684\n",
      "yes\n",
      "1685\n",
      "yes\n",
      "1686\n",
      "yes\n",
      "1687\n",
      "yes\n",
      "1688\n",
      "yes\n",
      "1689\n",
      "yes\n",
      "1690\n",
      "yes\n",
      "1691\n",
      "yes\n",
      "1692\n",
      "yes\n",
      "1693\n",
      "yes\n",
      "1694\n",
      "yes\n",
      "1695\n",
      "yes\n",
      "1696\n",
      "yes\n",
      "1697\n",
      "yes\n",
      "1698\n",
      "yes\n",
      "1699\n",
      "yes\n",
      "1700\n",
      "yes\n",
      "1701\n",
      "yes\n",
      "1702\n",
      "yes\n",
      "1703\n",
      "yes\n",
      "1704\n",
      "yes\n",
      "1705\n",
      "yes\n",
      "1706\n",
      "yes\n",
      "1707\n",
      "yes\n",
      "1708\n",
      "yes\n",
      "1709\n",
      "yes\n",
      "1710\n",
      "yes\n",
      "1711\n",
      "yes\n",
      "1712\n",
      "yes\n",
      "1713\n",
      "yes\n",
      "1714\n",
      "yes\n",
      "1715\n",
      "yes\n",
      "1716\n",
      "yes\n",
      "1717\n",
      "yes\n",
      "1718\n",
      "yes\n",
      "1719\n",
      "yes\n",
      "1720\n",
      "yes\n",
      "1721\n",
      "yes\n",
      "1722\n",
      "yes\n",
      "1723\n",
      "yes\n",
      "1724\n",
      "yes\n",
      "1725\n",
      "yes\n",
      "1726\n",
      "yes\n",
      "1727\n",
      "yes\n",
      "1728\n",
      "yes\n",
      "1729\n",
      "yes\n",
      "1730\n",
      "yes\n",
      "1731\n",
      "yes\n",
      "1732\n",
      "yes\n",
      "1733\n",
      "yes\n",
      "1734\n",
      "yes\n",
      "1735\n",
      "yes\n",
      "1736\n",
      "yes\n",
      "1737\n",
      "yes\n",
      "1738\n",
      "yes\n",
      "1739\n",
      "yes\n",
      "1740\n",
      "yes\n",
      "1741\n",
      "yes\n",
      "1742\n",
      "yes\n",
      "1743\n",
      "yes\n",
      "1744\n",
      "yes\n",
      "1745\n",
      "yes\n",
      "1746\n",
      "yes\n",
      "1747\n",
      "yes\n",
      "1748\n",
      "yes\n",
      "1749\n",
      "yes\n",
      "1750\n",
      "yes\n",
      "1751\n",
      "yes\n",
      "1752\n",
      "yes\n",
      "1753\n",
      "yes\n",
      "1754\n",
      "yes\n",
      "1755\n",
      "yes\n",
      "1756\n",
      "yes\n",
      "1757\n",
      "yes\n",
      "1758\n",
      "yes\n",
      "1759\n",
      "yes\n",
      "1760\n",
      "yes\n",
      "1761\n",
      "yes\n",
      "1762\n",
      "yes\n",
      "1763\n",
      "yes\n",
      "1764\n",
      "yes\n",
      "1765\n",
      "yes\n",
      "1766\n",
      "yes\n",
      "1767\n",
      "yes\n",
      "1768\n",
      "yes\n",
      "1769\n",
      "yes\n",
      "1770\n",
      "yes\n",
      "1771\n",
      "yes\n",
      "1772\n",
      "yes\n",
      "1773\n",
      "yes\n",
      "1774\n",
      "yes\n",
      "1775\n",
      "yes\n",
      "1776\n",
      "yes\n",
      "1777\n",
      "yes\n",
      "1778\n",
      "yes\n",
      "1779\n",
      "yes\n",
      "1780\n",
      "yes\n",
      "1781\n",
      "yes\n",
      "1782\n",
      "yes\n",
      "1783\n",
      "yes\n",
      "1784\n",
      "yes\n",
      "1785\n",
      "yes\n",
      "1786\n",
      "yes\n",
      "1787\n",
      "yes\n",
      "1788\n",
      "yes\n",
      "1789\n",
      "yes\n",
      "1790\n",
      "yes\n",
      "1791\n",
      "yes\n",
      "1792\n",
      "yes\n",
      "1793\n",
      "yes\n",
      "1794\n",
      "yes\n",
      "1795\n",
      "yes\n",
      "1796\n",
      "yes\n",
      "1797\n",
      "yes\n",
      "1798\n",
      "yes\n",
      "1799\n",
      "yes\n",
      "1800\n",
      "yes\n",
      "1801\n",
      "yes\n",
      "1802\n",
      "yes\n",
      "1803\n",
      "yes\n",
      "1804\n",
      "yes\n",
      "1805\n",
      "yes\n",
      "1806\n",
      "yes\n",
      "1807\n",
      "yes\n",
      "1808\n",
      "yes\n",
      "1809\n",
      "yes\n",
      "1810\n",
      "yes\n",
      "1811\n",
      "yes\n",
      "1812\n",
      "yes\n",
      "1813\n",
      "yes\n",
      "1814\n",
      "yes\n",
      "1815\n",
      "yes\n",
      "1816\n",
      "yes\n",
      "1817\n",
      "yes\n",
      "1818\n",
      "yes\n",
      "1819\n",
      "yes\n",
      "1820\n",
      "yes\n",
      "1821\n",
      "yes\n",
      "1822\n",
      "yes\n",
      "1823\n",
      "yes\n",
      "1824\n",
      "yes\n",
      "1825\n",
      "yes\n",
      "1826\n",
      "yes\n",
      "1827\n",
      "yes\n",
      "1828\n",
      "yes\n",
      "1829\n",
      "yes\n",
      "1830\n",
      "yes\n",
      "1831\n",
      "yes\n",
      "1832\n",
      "yes\n",
      "1833\n",
      "yes\n",
      "1834\n",
      "yes\n",
      "1835\n",
      "yes\n",
      "1836\n",
      "yes\n",
      "1837\n",
      "yes\n",
      "1838\n",
      "yes\n",
      "1839\n",
      "yes\n",
      "1840\n",
      "yes\n",
      "1841\n",
      "yes\n",
      "1842\n",
      "yes\n",
      "1843\n",
      "yes\n",
      "1844\n",
      "yes\n",
      "1845\n",
      "yes\n",
      "1846\n",
      "yes\n",
      "1847\n",
      "yes\n",
      "1848\n",
      "yes\n",
      "1849\n",
      "yes\n",
      "1850\n",
      "yes\n",
      "1851\n",
      "yes\n",
      "1852\n",
      "yes\n",
      "1853\n",
      "yes\n",
      "1854\n",
      "yes\n",
      "1855\n",
      "yes\n",
      "1856\n",
      "yes\n",
      "1857\n",
      "yes\n",
      "1858\n",
      "yes\n",
      "1859\n",
      "yes\n",
      "1860\n",
      "yes\n",
      "1861\n",
      "yes\n",
      "1862\n",
      "yes\n",
      "1863\n",
      "yes\n",
      "1864\n",
      "yes\n",
      "1865\n",
      "yes\n",
      "1866\n",
      "yes\n",
      "1867\n",
      "yes\n",
      "1868\n",
      "yes\n",
      "1869\n",
      "yes\n",
      "1870\n",
      "yes\n",
      "1871\n",
      "yes\n",
      "1872\n",
      "yes\n",
      "1873\n",
      "yes\n",
      "1874\n",
      "yes\n",
      "1875\n",
      "yes\n",
      "1876\n",
      "yes\n",
      "1877\n",
      "yes\n",
      "1878\n",
      "yes\n",
      "1879\n",
      "yes\n",
      "1880\n",
      "yes\n",
      "1881\n",
      "yes\n",
      "1882\n",
      "yes\n",
      "1883\n",
      "yes\n",
      "1884\n",
      "yes\n",
      "1885\n",
      "yes\n",
      "1886\n",
      "yes\n",
      "1887\n",
      "yes\n",
      "1888\n",
      "yes\n",
      "1889\n",
      "yes\n",
      "1890\n",
      "yes\n",
      "1891\n",
      "yes\n",
      "1892\n",
      "yes\n",
      "1893\n",
      "yes\n",
      "1894\n",
      "yes\n",
      "1895\n",
      "yes\n",
      "1896\n",
      "yes\n",
      "1897\n",
      "yes\n",
      "1898\n",
      "yes\n",
      "1899\n",
      "yes\n",
      "1900\n",
      "yes\n",
      "1901\n",
      "yes\n",
      "1902\n",
      "yes\n",
      "1903\n",
      "yes\n",
      "1904\n",
      "yes\n",
      "1905\n",
      "yes\n",
      "1906\n",
      "yes\n",
      "1907\n",
      "yes\n",
      "1908\n",
      "yes\n",
      "1909\n",
      "yes\n",
      "1910\n",
      "yes\n",
      "1911\n",
      "yes\n",
      "1912\n",
      "yes\n",
      "1913\n",
      "yes\n",
      "1914\n",
      "yes\n",
      "1915\n",
      "yes\n",
      "1916\n",
      "yes\n",
      "1917\n",
      "yes\n",
      "1918\n",
      "yes\n",
      "1919\n",
      "yes\n",
      "1920\n",
      "yes\n",
      "1921\n",
      "yes\n",
      "1922\n",
      "yes\n",
      "1923\n",
      "yes\n",
      "1924\n",
      "yes\n",
      "1925\n",
      "yes\n",
      "1926\n",
      "yes\n",
      "1927\n",
      "yes\n",
      "1928\n",
      "yes\n",
      "1929\n",
      "yes\n",
      "1930\n",
      "yes\n",
      "1931\n",
      "yes\n",
      "1932\n",
      "yes\n",
      "1933\n",
      "yes\n",
      "1934\n",
      "yes\n",
      "1935\n",
      "yes\n",
      "1936\n",
      "yes\n",
      "1937\n",
      "yes\n",
      "1938\n",
      "yes\n",
      "1939\n",
      "yes\n",
      "1940\n",
      "yes\n",
      "1941\n",
      "yes\n",
      "1942\n",
      "yes\n",
      "1943\n",
      "yes\n",
      "1944\n",
      "yes\n",
      "1945\n",
      "yes\n",
      "1946\n",
      "yes\n",
      "1947\n",
      "yes\n",
      "1948\n",
      "yes\n",
      "1949\n",
      "yes\n",
      "1950\n",
      "yes\n",
      "1951\n",
      "yes\n"
     ]
    }
   ],
   "source": [
    "class SequenceFolder(data.Dataset):\n",
    "    def __init__(self,root):\n",
    "        self.dataset=root\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "#         print(len(self.dataset))\n",
    "        return len(self.dataset)       \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "         return (np.array(total_gene[index]) ,np.array(total_label[index]))\n",
    "#         print(self.dataset['gen_name'][index])          \n",
    "#         try:\n",
    "           \n",
    "#         except :\n",
    "            \n",
    "total_set=SequenceFolder(df)  \n",
    "print(len(total_set))\n",
    "u=0\n",
    "for x in total_set:\n",
    "    print(u)\n",
    "#     print(x)\n",
    "    u=u+1\n",
    "    print(\"yes\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(total_set)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(total_set, batch_size=batch_size, \n",
    "                                           sampler=train_sampler,drop_last=True)\n",
    "validation_loader = torch.utils.data.DataLoader(total_set, batch_size=batch_size,\n",
    "                                                sampler=valid_sampler,drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n",
      "torch.Size([4, 70, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "for x,y in validation_loader:\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun 11 22:50:54 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 384.111                Driver Version: 384.111                   |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:04:00.0  On |                  N/A |\n",
      "| 57%   73C    P2   136W / 250W |   2565MiB / 11172MiB |     30%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 49%   83C    P2   161W / 250W |   5497MiB / 11172MiB |     88%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce GTX 108...  Off  | 00000000:08:00.0 Off |                  N/A |\n",
      "| 77%   83C    P2   181W / 250W |   7729MiB / 11172MiB |     98%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce GTX 108...  Off  | 00000000:0A:00.0 Off |                  N/A |\n",
      "| 39%   67C    P2   162W / 250W |   9391MiB / 11172MiB |     90%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce GTX 108...  Off  | 00000000:85:00.0 Off |                  N/A |\n",
      "| 85%   86C    P2   139W / 250W |   9734MiB / 11172MiB |     71%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce GTX 108...  Off  | 00000000:86:00.0 Off |                  N/A |\n",
      "| 31%   54C    P8    19W / 250W |   7976MiB / 11172MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce GTX 108...  Off  | 00000000:89:00.0 Off |                  N/A |\n",
      "| 26%   47C    P2    58W / 250W |    774MiB / 11172MiB |     23%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce GTX 108...  Off  | 00000000:8A:00.0 Off |                  N/A |\n",
      "| 56%   72C    P2   133W / 250W |   6742MiB / 11172MiB |     97%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      5857      G   /usr/lib/xorg/Xorg                            50MiB |\n",
      "|    0     24061      C   ...ratik/anaconda2/envs/kaiser/bin/python3   553MiB |\n",
      "|    0     25119      C   python                                       821MiB |\n",
      "|    0     27009      C   ...ratik/anaconda2/envs/kaiser/bin/python3   605MiB |\n",
      "|    0     37172      C   ...ratik/anaconda2/envs/kaiser/bin/python3   523MiB |\n",
      "|    1      2327      C   ...amalpcs17/anaconda3_sockeye/bin/python3  5059MiB |\n",
      "|    1     24693      C   python                                       425MiB |\n",
      "|    2      3601      C   ...amalpcs17/anaconda3_sockeye/bin/python3  4575MiB |\n",
      "|    2     42547      C   python                                      3143MiB |\n",
      "|    3      4141      C   ...amalpcs17/anaconda3_sockeye/bin/python3  7841MiB |\n",
      "|    3     13670      C   python                                       225MiB |\n",
      "|    3     20910      C   ...kamalpcs17/anaconda3_sockeye/bin/python   831MiB |\n",
      "|    3     31976      C   python                                       483MiB |\n",
      "|    4      7265      C   ...ratik/anaconda2/envs/kaiser/bin/python3   487MiB |\n",
      "|    4     27504      C   ...ratik/anaconda2/envs/kaiser/bin/python3   293MiB |\n",
      "|    4     30944      C   ...ratik/anaconda2/envs/kaiser/bin/python3  4135MiB |\n",
      "|    4     39564      C   ...ratik/anaconda2/envs/kaiser/bin/python3  1611MiB |\n",
      "|    4     41877      C   ...ratik/anaconda2/envs/kaiser/bin/python3  3193MiB |\n",
      "|    5     48366      C   /usr/bin/python3                            7965MiB |\n",
      "|    6     28576      C   python                                       763MiB |\n",
      "|    7      3869      C   ...amalpcs17/anaconda3_sockeye/bin/python3  5989MiB |\n",
      "|    7     19669      C   /home1/dushyant/anaconda2/bin/python         219MiB |\n",
      "|    7     27504      C   ...ratik/anaconda2/envs/kaiser/bin/python3   517MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "lstm = nn.LSTM(input_size=4,hidden_size=200,bidirectional=True) #input_size hidden_size num_layers \n",
    "lstm2=nn.LSTM(input_size=400,hidden_size=200)\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.fc1=nn.Linear(200, 600)\n",
    "        self.bn1=nn.BatchNorm1d(num_features=600)\n",
    "        \n",
    "        self.relu=nn.ReLU(inplace=True)\n",
    "        self.fc2=nn.Linear(600, 300)\n",
    "        self.bn2=nn.BatchNorm1d(num_features=300)\n",
    "\n",
    "        self.fc3=nn.Linear(300, 100)\n",
    "        self.bn3=nn.BatchNorm1d(num_features=100)\n",
    "        \n",
    "        self.fc4=nn.Linear(100, 2)\n",
    "        self.sigm=nn.Sigmoid()\n",
    "        self.dropout1=nn.Dropout(0.2)\n",
    "        self.dropout2=nn.Dropout(0.3)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        y=self.sigm(self.fc4(self.bn3(self.fc3(self.bn2(self.dropout2(self.relu(self.fc2(self.bn1(self.dropout1(self.relu(self.fc1(x))))))))))))\n",
    "        return(y)\n",
    "    \n",
    "\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda:0'\n",
    "model1=lstm.to(device)\n",
    "model2=MLP().to(device)\n",
    "model3=lstm2.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optim_params = [\n",
    "    {'params': model1.parameters(), 'lr':0.0001},\n",
    "    {'params': model2.parameters(), 'lr':0.0001},\n",
    "    {'params': model3.parameters(), 'lr':0.0001}\n",
    "        \n",
    "]\n",
    "optimizer = torch.optim.Adam(optim_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch=10000\n",
    "#3, 50, 1, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(177, device='cuda:0') 388\n",
      "tensor([[128.,  65.],\n",
      "        [146.,  49.]])\n",
      "tensor(270.7516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(177, device='cuda:0') 388\n",
      "tensor([[126.,  67.],\n",
      "        [144.,  51.]])\n",
      "tensor(270.7054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(202, device='cuda:0') 388\n",
      "tensor([[139.,  54.],\n",
      "        [132.,  63.]])\n",
      "tensor(270.8701, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(193, device='cuda:0') 388\n",
      "tensor([[135.,  57.],\n",
      "        [138.,  58.]])\n",
      "tensor(270.5135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(205, device='cuda:0') 388\n",
      "tensor([[138.,  56.],\n",
      "        [127.,  67.]])\n",
      "tensor(270.8338, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(199, device='cuda:0') 388\n",
      "tensor([[137.,  56.],\n",
      "        [133.,  62.]])\n",
      "tensor(270.8381, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(187, device='cuda:0') 388\n",
      "tensor([[129.,  64.],\n",
      "        [137.,  58.]])\n",
      "tensor(270.1692, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(186, device='cuda:0') 388\n",
      "tensor([[122.,  71.],\n",
      "        [131.,  64.]])\n",
      "tensor(270.1494, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(187, device='cuda:0') 388\n",
      "tensor([[124.,  69.],\n",
      "        [132.,  63.]])\n",
      "tensor(270.8961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(194, device='cuda:0') 388\n",
      "tensor([[127.,  65.],\n",
      "        [129.,  67.]])\n",
      "tensor(270.1307, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(175, device='cuda:0') 388\n",
      "tensor([[115.,  79.],\n",
      "        [134.,  60.]])\n",
      "tensor(271.0100, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(186, device='cuda:0') 388\n",
      "tensor([[125.,  68.],\n",
      "        [134.,  61.]])\n",
      "tensor(270.4876, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(208, device='cuda:0') 388\n",
      "tensor([[134.,  60.],\n",
      "        [120.,  74.]])\n",
      "tensor(270.5880, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(205, device='cuda:0') 388\n",
      "tensor([[129.,  64.],\n",
      "        [119.,  76.]])\n",
      "tensor(270.5607, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(190, device='cuda:0') 388\n",
      "tensor([[127.,  66.],\n",
      "        [132.,  63.]])\n",
      "tensor(270.0286, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(197, device='cuda:0') 388\n",
      "tensor([[130.,  64.],\n",
      "        [127.,  67.]])\n",
      "tensor(270.8212, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(203, device='cuda:0') 388\n",
      "tensor([[143.,  51.],\n",
      "        [134.,  60.]])\n",
      "tensor(269.9119, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(203, device='cuda:0') 388\n",
      "tensor([[135.,  59.],\n",
      "        [126.,  68.]])\n",
      "tensor(270.8474, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(192, device='cuda:0') 388\n",
      "tensor([[127.,  67.],\n",
      "        [129.,  65.]])\n",
      "tensor(270.6659, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(180, device='cuda:0') 388\n",
      "tensor([[121.,  71.],\n",
      "        [137.,  59.]])\n",
      "tensor(269.9430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(199, device='cuda:0') 388\n",
      "tensor([[134.,  60.],\n",
      "        [129.,  65.]])\n",
      "tensor(270.3063, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(192, device='cuda:0') 388\n",
      "tensor([[127.,  66.],\n",
      "        [130.,  65.]])\n",
      "tensor(270.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(190, device='cuda:0') 388\n",
      "tensor([[123.,  70.],\n",
      "        [128.,  67.]])\n",
      "tensor(270.5052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(190, device='cuda:0') 388\n",
      "tensor([[129.,  64.],\n",
      "        [134.,  61.]])\n",
      "tensor(270.6416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(215, device='cuda:0') 388\n",
      "tensor([[137.,  55.],\n",
      "        [118.,  78.]])\n",
      "tensor(270.0419, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(189, device='cuda:0') 388\n",
      "tensor([[124.,  68.],\n",
      "        [131.,  65.]])\n",
      "tensor(270.1889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(188, device='cuda:0') 388\n",
      "tensor([[126.,  66.],\n",
      "        [134.,  62.]])\n",
      "tensor(269.9885, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(206, device='cuda:0') 388\n",
      "tensor([[135.,  57.],\n",
      "        [125.,  71.]])\n",
      "tensor(271.0143, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(197, device='cuda:0') 388\n",
      "tensor([[137.,  55.],\n",
      "        [136.,  60.]])\n",
      "tensor(270.4869, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(191, device='cuda:0') 388\n",
      "tensor([[135.,  57.],\n",
      "        [140.,  56.]])\n",
      "tensor(270.3592, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(204, device='cuda:0') 388\n",
      "tensor([[147.,  46.],\n",
      "        [138.,  57.]])\n",
      "tensor(270.7070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(197, device='cuda:0') 388\n",
      "tensor([[134.,  58.],\n",
      "        [133.,  63.]])\n",
      "tensor(270.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(178, device='cuda:0') 388\n",
      "tensor([[127.,  65.],\n",
      "        [145.,  51.]])\n",
      "tensor(270.0235, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(188, device='cuda:0') 388\n",
      "tensor([[129.,  63.],\n",
      "        [137.,  59.]])\n",
      "tensor(270.6176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(196, device='cuda:0') 388\n",
      "tensor([[136.,  58.],\n",
      "        [134.,  60.]])\n",
      "tensor(270.1602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(198, device='cuda:0') 388\n",
      "tensor([[134.,  59.],\n",
      "        [131.,  64.]])\n",
      "tensor(270.0114, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(200, device='cuda:0') 388\n",
      "tensor([[133.,  61.],\n",
      "        [127.,  67.]])\n",
      "tensor(270.6060, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(184, device='cuda:0') 388\n",
      "tensor([[124.,  69.],\n",
      "        [135.,  60.]])\n",
      "tensor(270.6256, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(198, device='cuda:0') 388\n",
      "tensor([[139.,  55.],\n",
      "        [135.,  59.]])\n",
      "tensor(270.7800, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(195, device='cuda:0') 388\n",
      "tensor([[131.,  61.],\n",
      "        [132.,  64.]])\n",
      "tensor(270.1728, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(205, device='cuda:0') 388\n",
      "tensor([[136.,  58.],\n",
      "        [125.,  69.]])\n",
      "tensor(270.6801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(199, device='cuda:0') 388\n",
      "tensor([[127.,  65.],\n",
      "        [124.,  72.]])\n",
      "tensor(270.5890, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(192, device='cuda:0') 388\n",
      "tensor([[131.,  63.],\n",
      "        [133.,  61.]])\n",
      "tensor(270.1764, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(186, device='cuda:0') 388\n",
      "tensor([[128.,  66.],\n",
      "        [136.,  58.]])\n",
      "tensor(270.4709, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(182, device='cuda:0') 388\n",
      "tensor([[121.,  71.],\n",
      "        [135.,  61.]])\n",
      "tensor(270.0229, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(198, device='cuda:0') 388\n",
      "tensor([[133.,  59.],\n",
      "        [131.,  65.]])\n",
      "tensor(270.1597, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(180, device='cuda:0') 388\n",
      "tensor([[119.,  73.],\n",
      "        [135.,  61.]])\n",
      "tensor(270.0059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(182, device='cuda:0') 388\n",
      "tensor([[129.,  63.],\n",
      "        [143.,  53.]])\n",
      "tensor(270.5061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(197, device='cuda:0') 388\n",
      "tensor([[139.,  53.],\n",
      "        [138.,  58.]])\n",
      "tensor(270.3978, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(199, device='cuda:0') 388\n",
      "tensor([[139.,  53.],\n",
      "        [136.,  60.]])\n",
      "tensor(270.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(191, device='cuda:0') 388\n",
      "tensor([[137.,  57.],\n",
      "        [140.,  54.]])\n",
      "tensor(270.4469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(200, device='cuda:0') 388\n",
      "tensor([[140.,  53.],\n",
      "        [135.,  60.]])\n",
      "tensor(270.2073, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(200, device='cuda:0') 388\n",
      "tensor([[141.,  52.],\n",
      "        [136.,  59.]])\n",
      "tensor(270.3783, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(203, device='cuda:0') 388\n",
      "tensor([[144.,  50.],\n",
      "        [135.,  59.]])\n",
      "tensor(270.1206, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(201, device='cuda:0') 388\n",
      "tensor([[142.,  50.],\n",
      "        [137.,  59.]])\n",
      "tensor(270.5963, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(203, device='cuda:0') 388\n",
      "tensor([[142.,  52.],\n",
      "        [133.,  61.]])\n",
      "tensor(270.6748, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(201, device='cuda:0') 388\n",
      "tensor([[137.,  57.],\n",
      "        [130.,  64.]])\n",
      "tensor(270.5827, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(187, device='cuda:0') 388\n",
      "tensor([[130.,  64.],\n",
      "        [137.,  57.]])\n",
      "tensor(270.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(185, device='cuda:0') 388\n",
      "tensor([[127.,  66.],\n",
      "        [137.,  58.]])\n",
      "tensor(270.5319, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(204, device='cuda:0') 388\n",
      "tensor([[131.,  61.],\n",
      "        [123.,  73.]])\n",
      "tensor(270.8465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(193, device='cuda:0') 388\n",
      "tensor([[129.,  63.],\n",
      "        [132.,  64.]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(269.9371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(202, device='cuda:0') 388\n",
      "tensor([[136.,  57.],\n",
      "        [129.,  66.]])\n",
      "tensor(270.3561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(195, device='cuda:0') 388\n",
      "tensor([[129.,  63.],\n",
      "        [130.,  66.]])\n",
      "tensor(270.6809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(182, device='cuda:0') 388\n",
      "tensor([[125.,  68.],\n",
      "        [138.,  57.]])\n",
      "tensor(270.0259, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(187, device='cuda:0') 388\n",
      "tensor([[123.,  70.],\n",
      "        [131.,  64.]])\n",
      "tensor(270.3875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(200, device='cuda:0') 388\n",
      "tensor([[133.,  61.],\n",
      "        [127.,  67.]])\n",
      "tensor(270.0122, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(194, device='cuda:0') 388\n",
      "tensor([[132.,  61.],\n",
      "        [133.,  62.]])\n",
      "tensor(270.4535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(185, device='cuda:0') 388\n",
      "tensor([[124.,  68.],\n",
      "        [135.,  61.]])\n",
      "tensor(269.9643, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(192, device='cuda:0') 388\n",
      "tensor([[123.,  70.],\n",
      "        [126.,  69.]])\n",
      "tensor(270.2474, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(201, device='cuda:0') 388\n",
      "tensor([[136.,  57.],\n",
      "        [130.,  65.]])\n",
      "tensor(269.7808, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(197, device='cuda:0') 388\n",
      "tensor([[128.,  65.],\n",
      "        [126.,  69.]])\n",
      "tensor(270.2800, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(191, device='cuda:0') 388\n",
      "tensor([[129.,  64.],\n",
      "        [133.,  62.]])\n",
      "tensor(270.5054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(184, device='cuda:0') 388\n",
      "tensor([[125.,  69.],\n",
      "        [135.,  59.]])\n",
      "tensor(270.4017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(184, device='cuda:0') 388\n",
      "tensor([[126.,  66.],\n",
      "        [138.,  58.]])\n",
      "tensor(270.3260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(191, device='cuda:0') 388\n",
      "tensor([[124.,  70.],\n",
      "        [127.,  67.]])\n",
      "tensor(270.1889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(192, device='cuda:0') 388\n",
      "tensor([[125.,  67.],\n",
      "        [129.,  67.]])\n",
      "tensor(270.4878, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(202, device='cuda:0') 388\n",
      "tensor([[131.,  62.],\n",
      "        [124.,  71.]])\n",
      "tensor(270.5778, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(204, device='cuda:0') 388\n",
      "tensor([[129.,  64.],\n",
      "        [120.,  75.]])\n",
      "tensor(270.4814, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(197, device='cuda:0') 388\n",
      "tensor([[124.,  69.],\n",
      "        [122.,  73.]])\n",
      "tensor(270.4257, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(209, device='cuda:0') 388\n",
      "tensor([[137.,  57.],\n",
      "        [122.,  72.]])\n",
      "tensor(270.3196, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(186, device='cuda:0') 388\n",
      "tensor([[127.,  65.],\n",
      "        [137.,  59.]])\n",
      "tensor(270.4521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(190, device='cuda:0') 388\n",
      "tensor([[120.,  73.],\n",
      "        [125.,  70.]])\n",
      "tensor(270.2678, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(200, device='cuda:0') 388\n",
      "tensor([[121.,  72.],\n",
      "        [116.,  79.]])\n",
      "tensor(270.2042, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(201, device='cuda:0') 388\n",
      "tensor([[120.,  74.],\n",
      "        [113.,  81.]])\n",
      "tensor(270.5087, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(184, device='cuda:0') 388\n",
      "tensor([[112.,  80.],\n",
      "        [124.,  72.]])\n",
      "tensor(270.4432, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(192, device='cuda:0') 388\n",
      "tensor([[112.,  81.],\n",
      "        [115.,  80.]])\n",
      "tensor(270.3172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(202, device='cuda:0') 388\n",
      "tensor([[126.,  67.],\n",
      "        [119.,  76.]])\n",
      "tensor(270.1859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(190, device='cuda:0') 388\n",
      "tensor([[119.,  73.],\n",
      "        [125.,  71.]])\n",
      "tensor(270.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(190, device='cuda:0') 388\n",
      "tensor([[117.,  77.],\n",
      "        [121.,  73.]])\n",
      "tensor(270.6920, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(195, device='cuda:0') 388\n",
      "tensor([[118.,  75.],\n",
      "        [118.,  77.]])\n",
      "tensor(270.2662, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(201, device='cuda:0') 388\n",
      "tensor([[121.,  72.],\n",
      "        [115.,  80.]])\n",
      "tensor(270.6337, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(176, device='cuda:0') 388\n",
      "tensor([[108.,  85.],\n",
      "        [127.,  68.]])\n",
      "tensor(270.4641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(210, device='cuda:0') 388\n",
      "tensor([[118.,  76.],\n",
      "        [102.,  92.]])\n",
      "tensor(270.2982, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(171, device='cuda:0') 388\n",
      "tensor([[105.,  87.],\n",
      "        [130.,  66.]])\n",
      "tensor(270.5784, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(195, device='cuda:0') 388\n",
      "tensor([[116.,  76.],\n",
      "        [117.,  79.]])\n",
      "tensor(270.5555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(194, device='cuda:0') 388\n",
      "tensor([[122.,  72.],\n",
      "        [122.,  72.]])\n",
      "tensor(270.2181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(189, device='cuda:0') 388\n",
      "tensor([[119.,  75.],\n",
      "        [124.,  70.]])\n",
      "tensor(270.1472, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(182, device='cuda:0') 388\n",
      "tensor([[112.,  81.],\n",
      "        [125.,  70.]])\n",
      "tensor(270.1756, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(210, device='cuda:0') 388\n",
      "tensor([[131.,  61.],\n",
      "        [117.,  79.]])\n",
      "tensor(270.4763, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(193, device='cuda:0') 388\n",
      "tensor([[121.,  73.],\n",
      "        [122.,  72.]])\n",
      "tensor(270.6796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(189, device='cuda:0') 388\n",
      "tensor([[120.,  73.],\n",
      "        [126.,  69.]])\n",
      "tensor(270.0941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(194, device='cuda:0') 388\n",
      "tensor([[122.,  72.],\n",
      "        [122.,  72.]])\n",
      "tensor(270.0974, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(197, device='cuda:0') 388\n",
      "tensor([[127.,  66.],\n",
      "        [125.,  70.]])\n",
      "tensor(270.3444, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(210, device='cuda:0') 388\n",
      "tensor([[125.,  67.],\n",
      "        [111.,  85.]])\n",
      "tensor(270.6084, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(207, device='cuda:0') 388\n",
      "tensor([[129.,  63.],\n",
      "        [118.,  78.]])\n",
      "tensor(270.5364, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(198, device='cuda:0') 388\n",
      "tensor([[117.,  76.],\n",
      "        [114.,  81.]])\n",
      "tensor(270.2895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(197, device='cuda:0') 388\n",
      "tensor([[120.,  72.],\n",
      "        [119.,  77.]])\n",
      "tensor(270.3842, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(205, device='cuda:0') 388\n",
      "tensor([[121.,  71.],\n",
      "        [112.,  84.]])\n",
      "tensor(270.2839, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(188, device='cuda:0') 388\n",
      "tensor([[116.,  77.],\n",
      "        [123.,  72.]])\n",
      "tensor(270.6832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(201, device='cuda:0') 388\n",
      "tensor([[130.,  63.],\n",
      "        [124.,  71.]])\n",
      "tensor(270.0040, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(192, device='cuda:0') 388\n",
      "tensor([[121.,  72.],\n",
      "        [124.,  71.]])\n",
      "tensor(270.1013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(194, device='cuda:0') 388\n",
      "tensor([[113.,  80.],\n",
      "        [114.,  81.]])\n",
      "tensor(270.5497, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(190, device='cuda:0') 388\n",
      "tensor([[116.,  78.],\n",
      "        [120.,  74.]])\n",
      "tensor(270.4448, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(191, device='cuda:0') 388\n",
      "tensor([[123.,  71.],\n",
      "        [126.,  68.]])\n",
      "tensor(270.3914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(193, device='cuda:0') 388\n",
      "tensor([[114.,  80.],\n",
      "        [115.,  79.]])\n",
      "tensor(270.2069, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(199, device='cuda:0') 388\n",
      "tensor([[116.,  77.],\n",
      "        [112.,  83.]])\n",
      "tensor(270.2628, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(198, device='cuda:0') 388\n",
      "tensor([[121.,  73.],\n",
      "        [117.,  77.]])\n",
      "tensor(270.4806, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(199, device='cuda:0') 388\n",
      "tensor([[123.,  70.],\n",
      "        [119.,  76.]])\n",
      "tensor(270.5260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(187, device='cuda:0') 388\n",
      "tensor([[118.,  75.],\n",
      "        [126.,  69.]])\n",
      "tensor(270.2847, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(189, device='cuda:0') 388\n",
      "tensor([[119.,  74.],\n",
      "        [125.,  70.]])\n",
      "tensor(270.2548, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(191, device='cuda:0') 388\n",
      "tensor([[118.,  75.],\n",
      "        [122.,  73.]])\n",
      "tensor(270.1700, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(202, device='cuda:0') 388\n",
      "tensor([[127.,  66.],\n",
      "        [120.,  75.]])\n",
      "tensor(270.5819, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(171, device='cuda:0') 388\n",
      "tensor([[106.,  87.],\n",
      "        [130.,  65.]])\n",
      "tensor(270.3129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(207, device='cuda:0') 388\n",
      "tensor([[119.,  75.],\n",
      "        [106.,  88.]])\n",
      "tensor(270.3893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(180, device='cuda:0') 388\n",
      "tensor([[105.,  88.],\n",
      "        [120.,  75.]])\n",
      "tensor(270.8294, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(192, device='cuda:0') 388\n",
      "tensor([[116.,  77.],\n",
      "        [119.,  76.]])\n",
      "tensor(270.4316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(188, device='cuda:0') 388\n",
      "tensor([[112.,  80.],\n",
      "        [120.,  76.]])\n",
      "tensor(270.1722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(183, device='cuda:0') 388\n",
      "tensor([[113.,  80.],\n",
      "        [125.,  70.]])\n",
      "tensor(270.0664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(195, device='cuda:0') 388\n",
      "tensor([[115.,  78.],\n",
      "        [115.,  80.]])\n",
      "tensor(270.3705, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(178, device='cuda:0') 388\n",
      "tensor([[117.,  75.],\n",
      "        [135.,  61.]])\n",
      "tensor(270.5053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(194, device='cuda:0') 388\n",
      "tensor([[125.,  67.],\n",
      "        [127.,  69.]])\n",
      "tensor(270.1587, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(203, device='cuda:0') 388\n",
      "tensor([[133.,  60.],\n",
      "        [125.,  70.]])\n",
      "tensor(270.3557, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(206, device='cuda:0') 388\n",
      "tensor([[136.,  58.],\n",
      "        [124.,  70.]])\n",
      "tensor(270.1557, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(200, device='cuda:0') 388\n",
      "tensor([[129.,  64.],\n",
      "        [124.,  71.]])\n",
      "tensor(270.4282, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(186, device='cuda:0') 388\n",
      "tensor([[124.,  70.],\n",
      "        [132.,  62.]])\n",
      "tensor(270.4467, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(191, device='cuda:0') 388\n",
      "tensor([[128.,  65.],\n",
      "        [132.,  63.]])\n",
      "tensor(270.3797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(191, device='cuda:0') 388\n",
      "tensor([[131.,  62.],\n",
      "        [135.,  60.]])\n",
      "tensor(270.5278, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(189, device='cuda:0') 388\n",
      "tensor([[127.,  67.],\n",
      "        [132.,  62.]])\n",
      "tensor(270.2017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(198, device='cuda:0') 388\n",
      "tensor([[134.,  60.],\n",
      "        [130.,  64.]])\n",
      "tensor(270.3153, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(187, device='cuda:0') 388\n",
      "tensor([[126.,  68.],\n",
      "        [133.,  61.]])\n",
      "tensor(270.3282, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(190, device='cuda:0') 388\n",
      "tensor([[130.,  64.],\n",
      "        [134.,  60.]])\n",
      "tensor(270.7841, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(195, device='cuda:0') 388\n",
      "tensor([[136.,  58.],\n",
      "        [135.,  59.]])\n",
      "tensor(270.5165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(200, device='cuda:0') 388\n",
      "tensor([[136.,  56.],\n",
      "        [132.,  64.]])\n",
      "tensor(270.1355, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(177, device='cuda:0') 388\n",
      "tensor([[124.,  70.],\n",
      "        [141.,  53.]])\n",
      "tensor(270.2592, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(208, device='cuda:0') 388\n",
      "tensor([[143.,  49.],\n",
      "        [131.,  65.]])\n",
      "tensor(270.2959, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(198, device='cuda:0') 388\n",
      "tensor([[137.,  56.],\n",
      "        [134.,  61.]])\n",
      "tensor(270.3813, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(201, device='cuda:0') 388\n",
      "tensor([[132.,  62.],\n",
      "        [125.,  69.]])\n",
      "tensor(270.7079, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(204, device='cuda:0') 388\n",
      "tensor([[138.,  55.],\n",
      "        [129.,  66.]])\n",
      "tensor(270.3950, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(196, device='cuda:0') 388\n",
      "tensor([[137.,  57.],\n",
      "        [135.,  59.]])\n",
      "tensor(270.0801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(209, device='cuda:0') 388\n",
      "tensor([[146.,  47.],\n",
      "        [132.,  63.]])\n",
      "tensor(270.1786, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(178, device='cuda:0') 388\n",
      "tensor([[130.,  63.],\n",
      "        [147.,  48.]])\n",
      "tensor(270.4676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(196, device='cuda:0') 388\n",
      "tensor([[138.,  54.],\n",
      "        [138.,  58.]])\n",
      "tensor(270.2981, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(187, device='cuda:0') 388\n",
      "tensor([[140.,  53.],\n",
      "        [148.,  47.]])\n",
      "tensor(270.5497, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(191, device='cuda:0') 388\n",
      "tensor([[141.,  52.],\n",
      "        [145.,  50.]])\n",
      "tensor(270.6083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(183, device='cuda:0') 388\n",
      "tensor([[137.,  56.],\n",
      "        [149.,  46.]])\n",
      "tensor(269.9606, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(186, device='cuda:0') 388\n",
      "tensor([[141.,  52.],\n",
      "        [150.,  45.]])\n",
      "tensor(270.4900, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(192, device='cuda:0') 388\n",
      "tensor([[135.,  58.],\n",
      "        [138.,  57.]])\n",
      "tensor(270.3930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(204, device='cuda:0') 388\n",
      "tensor([[144.,  48.],\n",
      "        [136.,  60.]])\n",
      "tensor(270.2287, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(210, device='cuda:0') 388\n",
      "tensor([[141.,  51.],\n",
      "        [127.,  69.]])\n",
      "tensor(270.4664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(194, device='cuda:0') 388\n",
      "tensor([[134.,  59.],\n",
      "        [135.,  60.]])\n",
      "tensor(270.4976, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(201, device='cuda:0') 388\n",
      "tensor([[142.,  52.],\n",
      "        [135.,  59.]])\n",
      "tensor(270.2448, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(181, device='cuda:0') 388\n",
      "tensor([[133.,  59.],\n",
      "        [148.,  48.]])\n",
      "tensor(270.4620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(185, device='cuda:0') 388\n",
      "tensor([[143.,  49.],\n",
      "        [154.,  42.]])\n",
      "tensor(270.3044, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(199, device='cuda:0') 388\n",
      "tensor([[152.,  41.],\n",
      "        [148.,  47.]])\n",
      "tensor(270.3853, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(176, device='cuda:0') 388\n",
      "tensor([[129.,  64.],\n",
      "        [148.,  47.]])\n",
      "tensor(270.4666, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(192, device='cuda:0') 388\n",
      "tensor([[139.,  53.],\n",
      "        [143.,  53.]])\n",
      "tensor(270.4157, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(186, device='cuda:0') 388\n",
      "tensor([[133.,  60.],\n",
      "        [142.,  53.]])\n",
      "tensor(270.4590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(183, device='cuda:0') 388\n",
      "tensor([[141.,  52.],\n",
      "        [153.,  42.]])\n",
      "tensor(270.2359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(202, device='cuda:0') 388\n",
      "tensor([[154.,  39.],\n",
      "        [147.,  48.]])\n",
      "tensor(270.6812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(205, device='cuda:0') 388\n",
      "tensor([[152.,  41.],\n",
      "        [142.,  53.]])\n",
      "tensor(270.5989, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(197, device='cuda:0') 388\n",
      "tensor([[142.,  51.],\n",
      "        [140.,  55.]])\n",
      "tensor(270.5966, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(207, device='cuda:0') 388\n",
      "tensor([[142.,  52.],\n",
      "        [129.,  65.]])\n",
      "tensor(270.3527, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(185, device='cuda:0') 388\n",
      "tensor([[132.,  61.],\n",
      "        [142.,  53.]])\n",
      "tensor(270.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(201, device='cuda:0') 388\n",
      "tensor([[143.,  50.],\n",
      "        [137.,  58.]])\n",
      "tensor(270.2321, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(196, device='cuda:0') 388\n",
      "tensor([[142.,  51.],\n",
      "        [141.,  54.]])\n",
      "tensor(270.1314, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(189, device='cuda:0') 388\n",
      "tensor([[139.,  53.],\n",
      "        [146.,  50.]])\n",
      "tensor(270.4078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(193, device='cuda:0') 388\n",
      "tensor([[140.,  54.],\n",
      "        [141.,  53.]])\n",
      "tensor(270.5066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(183, device='cuda:0') 388\n",
      "tensor([[130.,  62.],\n",
      "        [143.,  53.]])\n",
      "tensor(270.2697, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(196, device='cuda:0') 388\n",
      "tensor([[137.,  56.],\n",
      "        [136.,  59.]])\n",
      "tensor(270.1465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(199, device='cuda:0') 388\n",
      "tensor([[141.,  51.],\n",
      "        [138.,  58.]])\n",
      "tensor(270.4746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(182, device='cuda:0') 388\n",
      "tensor([[134.,  59.],\n",
      "        [147.,  48.]])\n",
      "tensor(270.2618, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(181, device='cuda:0') 388\n",
      "tensor([[141.,  53.],\n",
      "        [154.,  40.]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(270.3738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(190, device='cuda:0') 388\n",
      "tensor([[140.,  54.],\n",
      "        [144.,  50.]])\n",
      "tensor(270.2429, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(195, device='cuda:0') 388\n",
      "tensor([[145.,  49.],\n",
      "        [144.,  50.]])\n",
      "tensor(270.0989, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(198, device='cuda:0') 388\n",
      "tensor([[144.,  48.],\n",
      "        [142.,  54.]])\n",
      "tensor(270.5934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(176, device='cuda:0') 388\n",
      "tensor([[132.,  61.],\n",
      "        [151.,  44.]])\n",
      "tensor(270.4791, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(183, device='cuda:0') 388\n",
      "tensor([[140.,  53.],\n",
      "        [152.,  43.]])\n",
      "tensor(270.2680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(174, device='cuda:0') 388\n",
      "tensor([[139.,  54.],\n",
      "        [160.,  35.]])\n",
      "tensor(270.2914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(199, device='cuda:0') 388\n",
      "tensor([[153.,  41.],\n",
      "        [148.,  46.]])\n",
      "tensor(270.1954, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(183, device='cuda:0') 388\n",
      "tensor([[145.,  47.],\n",
      "        [158.,  38.]])\n",
      "tensor(270.5191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(194, device='cuda:0') 388\n",
      "tensor([[138.,  56.],\n",
      "        [138.,  56.]])\n",
      "tensor(270.5482, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(199, device='cuda:0') 388\n",
      "tensor([[133.,  60.],\n",
      "        [129.,  66.]])\n",
      "tensor(270.4091, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(187, device='cuda:0') 388\n",
      "tensor([[136.,  58.],\n",
      "        [143.,  51.]])\n",
      "tensor(270.3704, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(181, device='cuda:0') 388\n",
      "tensor([[136.,  57.],\n",
      "        [150.,  45.]])\n",
      "tensor(270.2320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(193, device='cuda:0') 388\n",
      "tensor([[142.,  51.],\n",
      "        [144.,  51.]])\n",
      "tensor(270.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(184, device='cuda:0') 388\n",
      "tensor([[137.,  56.],\n",
      "        [148.,  47.]])\n",
      "tensor(270.5314, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(187, device='cuda:0') 388\n",
      "tensor([[138.,  56.],\n",
      "        [145.,  49.]])\n",
      "tensor(270.4152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(199, device='cuda:0') 388\n",
      "tensor([[142.,  50.],\n",
      "        [139.,  57.]])\n",
      "tensor(270.3134, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(187, device='cuda:0') 388\n",
      "tensor([[144.,  49.],\n",
      "        [152.,  43.]])\n",
      "tensor(270.2837, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(195, device='cuda:0') 388\n",
      "tensor([[146.,  46.],\n",
      "        [147.,  49.]])\n",
      "tensor(270.3976, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(194, device='cuda:0') 388\n",
      "tensor([[141.,  53.],\n",
      "        [141.,  53.]])\n",
      "tensor(270.2836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(202, device='cuda:0') 388\n",
      "tensor([[141.,  51.],\n",
      "        [135.,  61.]])\n",
      "tensor(270.1378, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(192, device='cuda:0') 388\n",
      "tensor([[142.,  51.],\n",
      "        [145.,  50.]])\n",
      "tensor(270.3873, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(198, device='cuda:0') 388\n",
      "tensor([[143.,  51.],\n",
      "        [139.,  55.]])\n",
      "tensor(270.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(199, device='cuda:0') 388\n",
      "tensor([[143.,  50.],\n",
      "        [139.,  56.]])\n",
      "tensor(270.5266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(184, device='cuda:0') 388\n",
      "tensor([[130.,  63.],\n",
      "        [141.,  54.]])\n",
      "tensor(270.1706, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(184, device='cuda:0') 388\n",
      "tensor([[125.,  67.],\n",
      "        [137.,  59.]])\n",
      "tensor(270.5962, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(186, device='cuda:0') 388\n",
      "tensor([[129.,  65.],\n",
      "        [137.,  57.]])\n",
      "tensor(270.1810, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(184, device='cuda:0') 388\n",
      "tensor([[126.,  67.],\n",
      "        [137.,  58.]])\n",
      "tensor(270.3917, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(186, device='cuda:0') 388\n",
      "tensor([[126.,  68.],\n",
      "        [134.,  60.]])\n",
      "tensor(270.3925, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(207, device='cuda:0') 388\n",
      "tensor([[138.,  55.],\n",
      "        [126.,  69.]])\n",
      "tensor(269.9500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(196, device='cuda:0') 388\n",
      "tensor([[123.,  70.],\n",
      "        [122.,  73.]])\n",
      "tensor(270.0963, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(171, device='cuda:0') 388\n",
      "tensor([[110.,  83.],\n",
      "        [134.,  61.]])\n",
      "tensor(270.4929, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(210, device='cuda:0') 388\n",
      "tensor([[128.,  65.],\n",
      "        [113.,  82.]])\n",
      "tensor(270.4496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(196, device='cuda:0') 388\n",
      "tensor([[124.,  70.],\n",
      "        [122.,  72.]])\n",
      "tensor(270.3152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(184, device='cuda:0') 388\n",
      "tensor([[121.,  73.],\n",
      "        [131.,  63.]])\n",
      "tensor(270.2153, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(189, device='cuda:0') 388\n",
      "tensor([[118.,  75.],\n",
      "        [124.,  71.]])\n",
      "tensor(270.6358, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(187, device='cuda:0') 388\n",
      "tensor([[122.,  71.],\n",
      "        [130.,  65.]])\n",
      "tensor(270.4433, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(199, device='cuda:0') 388\n",
      "tensor([[125.,  68.],\n",
      "        [121.,  74.]])\n",
      "tensor(270.3928, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(202, device='cuda:0') 388\n",
      "tensor([[122.,  71.],\n",
      "        [115.,  80.]])\n",
      "tensor(270.5663, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(195, device='cuda:0') 388\n",
      "tensor([[119.,  74.],\n",
      "        [119.,  76.]])\n",
      "tensor(270.2781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(205, device='cuda:0') 388\n",
      "tensor([[124.,  68.],\n",
      "        [115.,  81.]])\n",
      "tensor(270.7065, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(200, device='cuda:0') 388\n",
      "tensor([[128.,  65.],\n",
      "        [123.,  72.]])\n",
      "tensor(270.3998, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(199, device='cuda:0') 388\n",
      "tensor([[122.,  72.],\n",
      "        [117.,  77.]])\n",
      "tensor(270.4543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(213, device='cuda:0') 388\n",
      "tensor([[134.,  60.],\n",
      "        [115.,  79.]])\n",
      "tensor(270.3187, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(187, device='cuda:0') 388\n",
      "tensor([[123.,  71.],\n",
      "        [130.,  64.]])\n",
      "tensor(270.3691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(189, device='cuda:0') 388\n",
      "tensor([[129.,  64.],\n",
      "        [135.,  60.]])\n",
      "tensor(270.2284, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(195, device='cuda:0') 388\n",
      "tensor([[133.,  60.],\n",
      "        [133.,  62.]])\n",
      "tensor(270.2928, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(212, device='cuda:0') 388\n",
      "tensor([[137.,  57.],\n",
      "        [119.,  75.]])\n",
      "tensor(270.3048, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(209, device='cuda:0') 388\n",
      "tensor([[133.,  59.],\n",
      "        [120.,  76.]])\n",
      "tensor(270.3218, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(197, device='cuda:0') 388\n",
      "tensor([[129.,  64.],\n",
      "        [127.,  68.]])\n",
      "tensor(270.3593, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(202, device='cuda:0') 388\n",
      "tensor([[126.,  67.],\n",
      "        [119.,  76.]])\n",
      "tensor(270.3179, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(215, device='cuda:0') 388\n",
      "tensor([[137.,  56.],\n",
      "        [117.,  78.]])\n",
      "tensor(270.3292, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(201, device='cuda:0') 388\n",
      "tensor([[127.,  67.],\n",
      "        [120.,  74.]])\n",
      "tensor(270.5857, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(184, device='cuda:0') 388\n",
      "tensor([[122.,  71.],\n",
      "        [133.,  62.]])\n",
      "tensor(270.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(179, device='cuda:0') 388\n",
      "tensor([[110.,  82.],\n",
      "        [127.,  69.]])\n",
      "tensor(270.1469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(204, device='cuda:0') 388\n",
      "tensor([[129.,  63.],\n",
      "        [121.,  75.]])\n",
      "tensor(270.4194, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(200, device='cuda:0') 388\n",
      "tensor([[129.,  65.],\n",
      "        [123.,  71.]])\n",
      "tensor(270.0250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(205, device='cuda:0') 388\n",
      "tensor([[125.,  68.],\n",
      "        [115.,  80.]])\n",
      "tensor(270.2168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(181, device='cuda:0') 388\n",
      "tensor([[114.,  78.],\n",
      "        [129.,  67.]])\n",
      "tensor(270.1648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(177, device='cuda:0') 388\n",
      "tensor([[106.,  86.],\n",
      "        [125.,  71.]])\n",
      "tensor(270.3652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(201, device='cuda:0') 388\n",
      "tensor([[110.,  83.],\n",
      "        [104.,  91.]])\n",
      "tensor(270.2394, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(221, device='cuda:0') 388\n",
      "tensor([[133.,  60.],\n",
      "        [107.,  88.]])\n",
      "tensor(270.4860, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(208, device='cuda:0') 388\n",
      "tensor([[122.,  70.],\n",
      "        [110.,  86.]])\n",
      "tensor(270.2176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(190, device='cuda:0') 388\n",
      "tensor([[113.,  81.],\n",
      "        [117.,  77.]])\n",
      "tensor(270.2719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(192, device='cuda:0') 388\n",
      "tensor([[106.,  86.],\n",
      "        [110.,  86.]])\n",
      "tensor(270.3759, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(203, device='cuda:0') 388\n",
      "tensor([[121.,  72.],\n",
      "        [113.,  82.]])\n",
      "tensor(270.3497, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(207, device='cuda:0') 388\n",
      "tensor([[127.,  66.],\n",
      "        [115.,  80.]])\n",
      "tensor(270.2158, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(188, device='cuda:0') 388\n",
      "tensor([[116.,  77.],\n",
      "        [123.,  72.]])\n",
      "tensor(270.3329, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(194, device='cuda:0') 388\n",
      "tensor([[124.,  68.],\n",
      "        [126.,  70.]])\n",
      "tensor(270.2976, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(214, device='cuda:0') 388\n",
      "tensor([[134.,  59.],\n",
      "        [115.,  80.]])\n",
      "tensor(270.4748, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(173, device='cuda:0') 388\n",
      "tensor([[113.,  80.],\n",
      "        [135.,  60.]])\n",
      "tensor(270.3603, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(192, device='cuda:0') 388\n",
      "tensor([[117.,  77.],\n",
      "        [119.,  75.]])\n",
      "tensor(270.5070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(193, device='cuda:0') 388\n",
      "tensor([[120.,  74.],\n",
      "        [121.,  73.]])\n",
      "tensor(270.2260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(198, device='cuda:0') 388\n",
      "tensor([[119.,  73.],\n",
      "        [117.,  79.]])\n",
      "tensor(270.2316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(198, device='cuda:0') 388\n",
      "tensor([[121.,  73.],\n",
      "        [117.,  77.]])\n",
      "tensor(270.6449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(191, device='cuda:0') 388\n",
      "tensor([[122.,  71.],\n",
      "        [126.,  69.]])\n",
      "tensor(270.4337, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(207, device='cuda:0') 388\n",
      "tensor([[129.,  65.],\n",
      "        [116.,  78.]])\n",
      "tensor(270.5685, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(200, device='cuda:0') 388\n",
      "tensor([[128.,  65.],\n",
      "        [123.,  72.]])\n",
      "tensor(270.4901, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(198, device='cuda:0') 388\n",
      "tensor([[134.,  59.],\n",
      "        [131.,  64.]])\n",
      "tensor(270.2956, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(198, device='cuda:0') 388\n",
      "tensor([[130.,  63.],\n",
      "        [127.,  68.]])\n",
      "tensor(270.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(205, device='cuda:0') 388\n",
      "tensor([[139.,  55.],\n",
      "        [128.,  66.]])\n",
      "tensor(270.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(190, device='cuda:0') 388\n",
      "tensor([[133.,  59.],\n",
      "        [139.,  57.]])\n",
      "tensor(270.3834, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(195, device='cuda:0') 388\n",
      "tensor([[140.,  53.],\n",
      "        [140.,  55.]])\n",
      "tensor(270.6265, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(199, device='cuda:0') 388\n",
      "tensor([[140.,  54.],\n",
      "        [135.,  59.]])\n",
      "tensor(270.4387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(195, device='cuda:0') 388\n",
      "tensor([[145.,  49.],\n",
      "        [144.,  50.]])\n",
      "tensor(270.3157, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(199, device='cuda:0') 388\n",
      "tensor([[142.,  51.],\n",
      "        [138.,  57.]])\n",
      "tensor(270.3470, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(187, device='cuda:0') 388\n",
      "tensor([[136.,  57.],\n",
      "        [144.,  51.]])\n",
      "tensor(270.3683, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(200, device='cuda:0') 388\n",
      "tensor([[148.,  45.],\n",
      "        [143.,  52.]])\n",
      "tensor(270.4965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(184, device='cuda:0') 388\n",
      "tensor([[138.,  55.],\n",
      "        [149.,  46.]])\n"
     ]
    }
   ],
   "source": [
    "for i in range(epoch):\n",
    "        total_correct=0\n",
    "        total=0\n",
    "        confusion_matrix = torch.zeros(2, 2)\n",
    "    \n",
    "        for GN,lab in (validation_loader):\n",
    "#             gen_nam=GN[0]\n",
    "           \n",
    "            seq=GN\n",
    "            seq=seq[:,:,0,:].permute(1,0,2)\n",
    "            \n",
    "            \n",
    "            \n",
    "            lab=lab.to(device)\n",
    "            inp=seq.to(device)\n",
    "        \n",
    "            if inp.shape[1]==2:\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            h0 = torch.zeros(2, 4, 200).to(device)   #(num_layers * num_directions, batch, hidden_size)\n",
    "            c0 = torch.zeros(2, 4, 200).to(device)\n",
    "            h_x2=c_x2=torch.zeros(1, 4, 200).to(device)\n",
    "            output, (hn, cn) = model1(inp, (h0, c0))  \n",
    "            output,(_,_)=model3(output,(h_x2,c_x2))\n",
    "#             print(output.shape)\n",
    "            q1,q2,q3=output.shape\n",
    "            out_last=((output[q1-1]))\n",
    "            \n",
    "            After_fc=model2(out_last)\n",
    "\n",
    "            _, preds = torch.max(After_fc, 1)\n",
    "            total_correct=total_correct+torch.sum(preds.long()==lab.long().to(device))\n",
    "            total=total+4\n",
    "            \n",
    "            for t, p in zip(lab.view(-1), preds.view(-1)):\n",
    " \n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "        print(total_correct,total)\n",
    "        print(confusion_matrix)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        loss_epoch=0\n",
    "        loss_batch=0\n",
    "        u=0\n",
    "        for GN,lab in (train_loader):\n",
    "            \n",
    "#             gen_nam=GN[0]\n",
    "            seq=GN\n",
    "            seq=seq[:,:,0,:].permute(1,0,2)\n",
    "            lab=lab.to(device)\n",
    "            inp=seq.to(device)\n",
    "#             print(inp.shape)\n",
    "\n",
    "             \n",
    "            h0 = torch.zeros(2, 4, 200).to(device)   #(num_layers * num_directions, batch, hidden_size)\n",
    "            c0 = torch.zeros(2, 4, 200).to(device)\n",
    "            if inp.shape[1]==2:\n",
    "                continue\n",
    "            output, (hn, cn) = model1(inp, (h0, c0)) \n",
    "            h_x2=c_x2=torch.zeros(1, 4, 200).to(device)\n",
    "            output,(_,_)=model3(output,(h_x2,c_x2))\n",
    "            \n",
    "\n",
    "            q1,q2,q3=output.shape\n",
    "            out_last=((output[q1-1]))\n",
    "            After_fc=model2(out_last)\n",
    "\n",
    "            loss = criterion(After_fc, lab).to(device)\n",
    "            loss_batch=loss\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "            u=u+1\n",
    "#             if u%4==0:\n",
    "            loss_epoch=loss_epoch+loss_batch\n",
    "            loss_batch.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "                \n",
    "        print(loss_epoch)\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model1.state_dict(), '1AnkitBiLSTMprostrate1.pt')\n",
    "torch.save(model2.state_dict(), '2AnkitBiLSTMprostrate2.pt')#2283/3908\n",
    "torch.save(model3.state_dict(), '3AnkitBiLSTMprostrate3.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
